"""
Moment Service - Extracts temporal narratives from resources.

Analyzes recent resources and sessions to identify temporal narratives
(meetings, coding sessions, conversations) and creates Moment entities
with temporal boundaries and metadata.
"""

import json
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Any, Optional
from uuid import uuid4

import yaml
from loguru import logger

from ...agentic.providers.pydantic_ai import create_agent
from ...agentic.serialization import serialize_agent_result
from ...models.entities.moment import Moment
from ...models.entities.resource import Resource
from ...models.entities.session import Session
from ...services.postgres.repository import Repository
from ...services.postgres.service import PostgresService


async def construct_moments(
    user_id: str,
    db: PostgresService,
    default_model: str = "gpt-4o",
    lookback_hours: int = 24,
    limit: Optional[int] = None,
) -> dict[str, Any]:
    """
    Extract moments from resources.

    Analyzes recent resources to identify temporal narratives
    (meetings, coding sessions, conversations) and creates
    Moment entities with temporal boundaries and metadata.

    Process:
    1. Query PostgreSQL for recent resources and sessions for this user
    2. Load MomentBuilder agent schema from filesystem
    3. Run agent to extract moments from data
    4. Create Moment entities via Repository
    5. Link moments to source resources via graph edges
    6. Embeddings auto-generated by embedding worker

    Args:
        user_id: User to process
        db: Database service (already connected)
        default_model: LLM model for analysis (default: gpt-4o)
        lookback_hours: Hours to look back (default: 24)
        limit: Max resources to process

    Returns:
        Statistics about moment construction
    """
    cutoff = datetime.now(timezone.utc) - timedelta(hours=lookback_hours)

    # Create repositories
    resource_repo = Repository(Resource, "resources", db=db)
    session_repo = Repository(Session, "sessions", db=db)
    moment_repo = Repository(Moment, "moments", db=db)

    # Query recent resources
    resources = await resource_repo.find(
        filters={
            "user_id": user_id,
        },
        order_by="resource_timestamp DESC",
        limit=limit,
    )

    # Filter by timestamp (SQL doesn't support comparisons in find yet)
    resources = [
        r for r in resources if r.resource_timestamp and r.resource_timestamp >= cutoff
    ]

    # Query recent sessions
    sessions = await session_repo.find(
        filters={
            "user_id": user_id,
        },
        order_by="created_at DESC",
        limit=limit,
    )

    # Filter by timestamp
    sessions = [s for s in sessions if s.created_at >= cutoff]

    if not resources and not sessions:
        return {
            "user_id": user_id,
            "lookback_hours": lookback_hours,
            "resources_queried": 0,
            "sessions_queried": 0,
            "moments_created": 0,
            "graph_edges_added": 0,
            "status": "no_data",
        }

    # Load MomentBuilder agent schema
    schema_path = (
        Path(__file__).parent.parent.parent
        / "schemas"
        / "agents"
        / "moment-builder.yaml"
    )

    if not schema_path.exists():
        raise FileNotFoundError(f"MomentBuilder schema not found: {schema_path}")

    with open(schema_path) as f:
        agent_schema = yaml.safe_load(f)

    # Prepare input data for agent
    input_data = {
        "resources": [
            {
                "id": r.id,
                "name": r.name,
                "category": r.category,
                "content": r.content,
                "resource_timestamp": (
                    r.resource_timestamp.isoformat() if r.resource_timestamp else None
                ),
            }
            for r in resources
        ],
        "sessions": [
            {
                "id": s.id,
                "query": s.query,
                "response": s.response,
                "created_at": s.created_at.isoformat(),
                "metadata": s.metadata,
            }
            for s in sessions
        ],
    }

    # Create and run MomentBuilder agent
    agent = await create_agent(
        agent_schema_override=agent_schema,
        model_override=default_model,
    )

    result = await agent.run(json.dumps(input_data, indent=2))

    # Serialize result (critical for Pydantic models!)
    output_data = serialize_agent_result(result.output)

    # Extract moments
    moments_data = output_data.get("moments", [])
    analysis_summary = output_data.get("analysis_summary", "")

    logger.info(
        f"MomentBuilder extracted {len(moments_data)} moments. Summary: {analysis_summary}"
    )

    # Create Moment entities
    created_moments = []
    total_edges = 0

    for moment_data in moments_data:
        # Map resource_timestamp/resource_ends_timestamp to starts_timestamp/ends_timestamp
        starts_ts_str = moment_data.get("resource_timestamp")
        ends_ts_str = moment_data.get("resource_ends_timestamp")

        if not starts_ts_str:
            logger.warning(f"Skipping moment without start timestamp: {moment_data.get('name')}")
            continue

        starts_ts = datetime.fromisoformat(starts_ts_str.replace("Z", "+00:00"))
        ends_ts = (
            datetime.fromisoformat(ends_ts_str.replace("Z", "+00:00"))
            if ends_ts_str
            else None
        )

        # Build graph edges to source resources
        source_resource_ids = moment_data.get("source_resource_ids", [])
        source_session_ids = moment_data.get("source_session_ids", [])

        graph_edges = []

        # Add edges to source resources
        for resource_id in source_resource_ids:
            graph_edges.append(
                {
                    "dst": resource_id,
                    "rel_type": "extracted_from",
                    "weight": 1.0,
                    "properties": {
                        "entity_type": "resource",
                        "extraction_method": "moment_builder_agent",
                    },
                    "created_at": datetime.now(timezone.utc).isoformat(),
                }
            )

        # Add edges to source sessions
        for session_id in source_session_ids:
            graph_edges.append(
                {
                    "dst": session_id,
                    "rel_type": "extracted_from",
                    "weight": 0.8,
                    "properties": {
                        "entity_type": "session",
                        "extraction_method": "moment_builder_agent",
                    },
                    "created_at": datetime.now(timezone.utc).isoformat(),
                }
            )

        # Create Moment entity
        moment = Moment(
            id=str(uuid4()),
            tenant_id=user_id,  # Set tenant_id = user_id
            user_id=user_id,
            name=moment_data.get("name"),
            moment_type=moment_data.get("moment_type"),
            category=moment_data.get("moment_type"),  # Use moment_type as category
            starts_timestamp=starts_ts,
            ends_timestamp=ends_ts,
            present_persons=[
                {"id": p["id"], "name": p["name"], "role": p.get("comment")}
                for p in moment_data.get("present_persons", [])
            ],
            emotion_tags=moment_data.get("emotion_tags", []),
            topic_tags=moment_data.get("topic_tags", []),
            summary=moment_data.get("content"),  # Use content as summary
            source_resource_ids=source_resource_ids,
            graph_edges=graph_edges,
            created_at=datetime.now(timezone.utc),
            updated_at=datetime.now(timezone.utc),
        )

        # Save to database (embeddings auto-generated by embedding worker)
        await moment_repo.upsert(moment)
        created_moments.append(moment)
        total_edges += len(graph_edges)

        logger.debug(
            f"Created moment: {moment.name} ({moment.moment_type}) with {len(graph_edges)} edges"
        )

    return {
        "user_id": user_id,
        "lookback_hours": lookback_hours,
        "resources_queried": len(resources),
        "sessions_queried": len(sessions),
        "moments_created": len(created_moments),
        "graph_edges_added": total_edges,
        "analysis_summary": analysis_summary,
        "status": "success",
    }
