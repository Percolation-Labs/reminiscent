apiVersion: postgresql.cnpg.io/v1
kind: Cluster
metadata:
  name: rem-postgres
  namespace: rem
spec:
  instances: 3
  primaryUpdateStrategy: unsupervised

  # Custom PostgreSQL 18 with pg_net extension baked in
  # Standard CNPG image works too - pg_net just won't be available
  # See: manifests/application/rem-stack/components/postgres/extensions/README.md
  imageName: percolationlabs/rem-pg:18

  bootstrap:
    initdb:
      database: remdb
      owner: remuser
      secret:
        name: rem-database-credentials
      # Run SQL migrations from ConfigMap on first startup
      # ConfigMap generated via: rem cluster generate

      # postInitSQL runs as superuser in postgres database context
      # Phoenix needs isolated database to avoid table conflicts (both have 'users' table)
      postInitSQL:
        - CREATE DATABASE phoenixdb OWNER remuser
        - GRANT ALL PRIVILEGES ON DATABASE phoenixdb TO remuser

      # postInitApplicationSQLRefs runs as app user in remdb context
      postInitApplicationSQLRefs:
        configMapRefs:
          - name: rem-postgres-init-sql
            key: 001_install.sql
          - name: rem-postgres-init-sql
            key: 002_install_models.sql
          - name: rem-postgres-init-sql
            key: 003_optional_extensions.sql

  # Storage configuration
  # Available storage classes (configured in CDK):
  #   - gp3: General purpose SSD (3,000 IOPS, 125 MB/s, $0.08/GB-month)
  #     * Good for dev/testing and cost-sensitive workloads
  #   - gp3-postgres: PostgreSQL-optimized SSD (5,000 IOPS, 250 MB/s, ~$0.09/GB-month)
  #     * Recommended for most production PostgreSQL workloads
  #     * Higher IOPS and throughput for WAL writes
  #   - io2-postgres: Mission-critical SSD (10,000 IOPS, ~$0.19/GB-month)
  #     * <1ms latency, 99.999% durability
  #     * Best for mission-critical production databases
  #     * 2x cost vs gp3-postgres
  #
  # Recommendation:
  #   - Dev/Testing: gp3 (current)
  #   - Production: gp3-postgres (most use cases)
  #   - Mission-Critical: io2-postgres (high-value data)
  storage:
    size: 50Gi
    storageClass: gp3  # Change to gp3-postgres for production, io2-postgres for mission-critical
    resizeInUseVolumes: true

  # Backup configuration to S3
  backup:
    barmanObjectStore:
      destinationPath: s3://${REM_BACKUP_BUCKET}/postgresql/rem-postgres
      s3Credentials:
        inheritFromIAMRole: true  # Use Pod Identity via service account
      wal:
        compression: gzip
        maxParallel: 4
      data:
        compression: gzip
        jobs: 4
        immediateCheckpoint: true
    retentionPolicy: "30d"

    # Volume snapshots for faster recovery
    volumeSnapshot:
      className: ebs-csi
      snapshotOwnerReference: cluster
      online: true
      onlineConfiguration:
        waitForArchive: true
        immediateCheckpoint: true

  # PostgreSQL configuration optimized for AI workloads
  postgresql:
    # pg_net requires shared_preload_libraries (extension baked into custom image)
    shared_preload_libraries:
      - pg_net

    parameters:
      # pg_net background worker database (must match where CREATE EXTENSION runs)
      pg_net.database_name: "remdb"
      # Connection settings
      max_connections: "300"

      # Memory settings (for 8GB pods)
      shared_buffers: "2GB"
      effective_cache_size: "6GB"
      maintenance_work_mem: "512MB"
      work_mem: "16MB"

      # WAL settings
      wal_buffers: "32MB"
      checkpoint_completion_target: "0.9"
      max_wal_size: "4GB"
      min_wal_size: "1GB"

      # Query planner
      default_statistics_target: "500"  # Higher for better vector query plans
      random_page_cost: "1.1"  # SSD-optimized
      effective_io_concurrency: "200"

      # Parallel query settings
      max_parallel_workers_per_gather: "4"
      max_parallel_workers: "8"
      max_worker_processes: "8"

      # pgvector-specific settings
      max_parallel_maintenance_workers: "4"

      # Autovacuum tuning for vector workloads
      autovacuum_max_workers: "4"
      autovacuum_naptime: "10s"

      # Logging
      log_checkpoints: "on"
      log_lock_waits: "on"
      log_temp_files: "0"
      log_autovacuum_min_duration: "0"

      # WAL archiving for PITR
      archive_mode: "on"
      archive_timeout: "5min"

  # Resource allocation
  resources:
    requests:
      memory: "4Gi"
      cpu: "2000m"
    limits:
      memory: "8Gi"
      cpu: "4000m"

  # Monitoring
  monitoring:
    enablePodMonitor: true
    podMonitorMetricRelabelings:
      - sourceLabels: [cluster]
        targetLabel: cnpg_cluster
        action: replace

  # Affinity rules for high availability
  # NOTE: nodeSelector/tolerations for dedicated stateful nodes are configured
  # in production overlay. Base config schedules on any node for MVP simplicity.
  affinity:
    enablePodAntiAffinity: true
    topologyKey: kubernetes.io/hostname
    podAntiAffinityType: required

  # Service account for Pod Identity (no annotations needed)
  serviceAccountTemplate:
    metadata:
      name: postgres-backup
