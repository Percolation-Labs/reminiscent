# Generated by: manifests/generate-sql-configmap.sh
# Date: 2025-11-20T00:40:28Z
# Source: rem/sql/migrations
# ConfigMap: 1 of 1
#
# This ConfigMap contains SQL initialization scripts for CloudNativePG.
# Referenced in postgres-cluster.yaml via bootstrap.initdb.postInitApplicationSQLRefs
#
# DO NOT EDIT MANUALLY - Regenerate with:
#   ./manifests/generate-sql-configmap.sh > manifests/application/rem-api/postgres-init-configmap.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  name: rem-postgres-init-sql
  namespace: siggy
  labels:
    app: rem-postgres
    component: database
    managed-by: kustomize
    migration-batch: "1"
data:
  001_install.sql: |
    -- REM Database Installation Script
    -- Description: Core database setup with extensions and infrastructure
    -- Version: 1.0.0
    -- Date: 2025-01-18
    --
    -- This script sets up:
    -- 1. Required PostgreSQL extensions (pgvector, pg_trgm, uuid-ossp)
    -- 2. Migration tracking table
    -- 3. KV_STORE UNLOGGED cache table
    -- 4. Helper functions
    --
    -- Usage:
    --   psql -d remdb -f sql/install.sql
    --
    -- Dependencies:
    --   - PostgreSQL 16+
    --   - pgvector extension compiled and available
    --   - pg_trgm extension (usually included)
    
    -- ============================================================================
    -- EXTENSIONS
    -- ============================================================================
    
    -- Enable pgvector extension for vector embeddings
    CREATE EXTENSION IF NOT EXISTS vector;
    
    -- Enable pg_trgm extension for fuzzy text search
    CREATE EXTENSION IF NOT EXISTS pg_trgm;
    
    -- Enable uuid-ossp for UUID generation
    CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
    
    -- Verify critical extensions
    DO $$
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_extension WHERE extname = 'vector') THEN
            RAISE EXCEPTION 'pgvector extension failed to install. Ensure pgvector is compiled and available.';
        END IF;
    
        IF NOT EXISTS (SELECT 1 FROM pg_extension WHERE extname = 'pg_trgm') THEN
            RAISE EXCEPTION 'pg_trgm extension failed to install.';
        END IF;
    
        RAISE NOTICE '✓ All required extensions installed successfully';
    END $$;
    
    -- ============================================================================
    -- MIGRATION TRACKING
    -- ============================================================================
    
    CREATE TABLE IF NOT EXISTS rem_migrations (
        id SERIAL PRIMARY KEY,
        name VARCHAR(255) NOT NULL UNIQUE,
        type VARCHAR(50) NOT NULL,  -- 'install', 'models', 'data'
        version VARCHAR(50),
        checksum VARCHAR(64),
        applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        applied_by VARCHAR(100) DEFAULT CURRENT_USER,
        execution_time_ms INTEGER,
        success BOOLEAN DEFAULT TRUE
    );
    
    CREATE INDEX IF NOT EXISTS idx_rem_migrations_type ON rem_migrations(type);
    CREATE INDEX IF NOT EXISTS idx_rem_migrations_applied_at ON rem_migrations(applied_at);
    
    COMMENT ON TABLE rem_migrations IS
    'Tracks all applied migrations including install scripts and model schema updates';
    
    -- ============================================================================
    -- KV_STORE CACHE
    -- ============================================================================
    
    -- KV_STORE: UNLOGGED table for O(1) entity lookups in REM
    --
    -- Design rationale:
    -- - UNLOGGED: Faster writes, no WAL overhead (acceptable for cache)
    -- - Rebuilds automatically from primary tables on restart
    -- - Supports LOOKUP queries with O(1) performance
    -- - Supports FUZZY queries with trigram indexes
    -- - User-scoped filtering when user_id IS NOT NULL
    -- - Tenant isolation via tenant_id
    --
    -- Schema:
    -- - entity_key: Natural language label (e.g., "sarah-chen", "project-alpha")
    -- - entity_type: Table name (e.g., "resources", "moments")
    -- - entity_id: UUID from primary table
    -- - tenant_id: Tenant identifier for multi-tenancy
    -- - user_id: Optional user scoping (NULL = system-level)
    -- - content_summary: Denormalized text for fuzzy search
    -- - metadata: JSONB for additional filtering
    -- - updated_at: Timestamp for cache invalidation
    
    CREATE UNLOGGED TABLE IF NOT EXISTS kv_store (
        entity_key VARCHAR(255) NOT NULL,
        entity_type VARCHAR(100) NOT NULL,
        entity_id UUID NOT NULL,
        tenant_id VARCHAR(100) NOT NULL,
        user_id VARCHAR(100),
        content_summary TEXT,
        metadata JSONB DEFAULT '{}',
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
        -- Composite primary key: entity_key unique per tenant
        PRIMARY KEY (tenant_id, entity_key)
    );
    
    -- Index for user-scoped lookups (when user_id IS NOT NULL)
    CREATE INDEX IF NOT EXISTS idx_kv_store_user ON kv_store (tenant_id, user_id)
    WHERE user_id IS NOT NULL;
    
    -- Index for entity_id reverse lookup (find key by ID)
    CREATE INDEX IF NOT EXISTS idx_kv_store_entity_id ON kv_store (entity_id);
    
    -- Trigram index for fuzzy text search (FUZZY queries)
    CREATE INDEX IF NOT EXISTS idx_kv_store_key_trgm ON kv_store
    USING gin (entity_key gin_trgm_ops);
    
    -- Trigram index for content_summary fuzzy search
    CREATE INDEX IF NOT EXISTS idx_kv_store_content_trgm ON kv_store
    USING gin (content_summary gin_trgm_ops);
    
    -- GIN index for metadata JSONB queries
    CREATE INDEX IF NOT EXISTS idx_kv_store_metadata ON kv_store
    USING gin (metadata);
    
    -- Index for entity_type filtering
    CREATE INDEX IF NOT EXISTS idx_kv_store_type ON kv_store (entity_type);
    
    -- Comments
    COMMENT ON TABLE kv_store IS
    'UNLOGGED cache for O(1) entity lookups. Supports REM LOOKUP and FUZZY queries. Rebuilt from primary tables on restart.';
    
    COMMENT ON COLUMN kv_store.entity_key IS
    'Natural language label for entity (e.g., "sarah-chen", "project-alpha")';
    
    COMMENT ON COLUMN kv_store.entity_type IS
    'Source table name (e.g., "resources", "moments", "users")';
    
    COMMENT ON COLUMN kv_store.entity_id IS
    'UUID from primary table for reverse lookup';
    
    COMMENT ON COLUMN kv_store.tenant_id IS
    'Tenant identifier for multi-tenancy isolation';
    
    COMMENT ON COLUMN kv_store.user_id IS
    'Optional user scoping. NULL = system-level entity, visible to all users in tenant';
    
    COMMENT ON COLUMN kv_store.content_summary IS
    'Denormalized text summary for fuzzy search. Concatenated from content fields.';
    
    -- ============================================================================
    -- HELPER FUNCTIONS
    -- ============================================================================
    
    -- Function to rebuild KV_STORE from primary tables
    -- Call this after database restart or manual cache invalidation
    CREATE OR REPLACE FUNCTION rebuild_kv_store()
    RETURNS TABLE(table_name TEXT, rows_inserted BIGINT) AS $$
    DECLARE
        table_rec RECORD;
        rows_affected BIGINT;
    BEGIN
        -- Clear existing cache
        DELETE FROM kv_store;
        RAISE NOTICE 'Cleared KV_STORE cache';
    
        -- Rebuild from each entity table
        -- This will be populated by triggers when install_models.sql is loaded
        -- For now, just return empty result
        RETURN;
    END;
    $$ LANGUAGE plpgsql;
    
    COMMENT ON FUNCTION rebuild_kv_store() IS
    'Rebuild KV_STORE cache from all entity tables. Call after database restart.';
    
    -- ============================================================================
    -- REM QUERY FUNCTIONS
    -- ============================================================================
    
    -- REM LOOKUP: O(1) entity lookup by natural key
    -- Returns entity metadata from KV_STORE cache
    CREATE OR REPLACE FUNCTION rem_lookup(
        p_entity_key VARCHAR(255),
        p_tenant_id VARCHAR(100),
        p_user_id VARCHAR(100) DEFAULT NULL
    )
    RETURNS TABLE(
        entity_key VARCHAR(255),
        entity_type VARCHAR(100),
        entity_id UUID,
        tenant_id VARCHAR(100),
        user_id VARCHAR(100),
        created_at TIMESTAMP,
        content_summary TEXT,
        metadata JSONB
    ) AS $$
    BEGIN
        RETURN QUERY
        SELECT
            kv.entity_key,
            kv.entity_type,
            kv.entity_id,
            kv.tenant_id,
            kv.user_id,
            kv.created_at,
            kv.content_summary,
            kv.metadata
        FROM kv_store kv
        WHERE kv.tenant_id = p_tenant_id
        AND kv.entity_key = p_entity_key
        AND (p_user_id IS NULL OR kv.user_id = p_user_id OR kv.user_id IS NULL);
    END;
    $$ LANGUAGE plpgsql STABLE;
    
    COMMENT ON FUNCTION rem_lookup IS
    'REM LOOKUP query: O(1) entity lookup by natural key with optional user scoping';
    
    -- REM FUZZY: Fuzzy text search using pg_trgm similarity
    -- Returns entities matching approximate text with similarity scores
    CREATE OR REPLACE FUNCTION rem_fuzzy(
        p_query TEXT,
        p_tenant_id VARCHAR(100),
        p_threshold REAL DEFAULT 0.3,
        p_limit INTEGER DEFAULT 10,
        p_user_id VARCHAR(100) DEFAULT NULL
    )
    RETURNS TABLE(
        entity_key VARCHAR(255),
        entity_type VARCHAR(100),
        entity_id UUID,
        tenant_id VARCHAR(100),
        user_id VARCHAR(100),
        created_at TIMESTAMP,
        content_summary TEXT,
        metadata JSONB,
        similarity_score REAL
    ) AS $$
    BEGIN
        RETURN QUERY
        SELECT
            kv.entity_key,
            kv.entity_type,
            kv.entity_id,
            kv.tenant_id,
            kv.user_id,
            kv.created_at,
            kv.content_summary,
            kv.metadata,
            similarity(kv.entity_key, p_query) AS similarity_score
        FROM kv_store kv
        WHERE kv.tenant_id = p_tenant_id
        AND (p_user_id IS NULL OR kv.user_id = p_user_id OR kv.user_id IS NULL)
        AND kv.entity_key % p_query  -- Trigram similarity operator
        ORDER BY similarity_score DESC
        LIMIT p_limit;
    END;
    $$ LANGUAGE plpgsql STABLE;
    
    COMMENT ON FUNCTION rem_fuzzy IS
    'REM FUZZY query: Fuzzy text search using pg_trgm with similarity scoring';
    
    -- REM TRAVERSE: Recursive graph traversal following edges
    -- Explores graph_edges starting from entity_key up to max_depth
    CREATE OR REPLACE FUNCTION rem_traverse(
        p_entity_key VARCHAR(255),
        p_tenant_id VARCHAR(100),
        p_max_depth INTEGER DEFAULT 1,
        p_rel_type VARCHAR(100) DEFAULT NULL,
        p_user_id VARCHAR(100) DEFAULT NULL
    )
    RETURNS TABLE(
        depth INTEGER,
        entity_key VARCHAR(255),
        entity_type VARCHAR(100),
        entity_id UUID,
        rel_type VARCHAR(100),
        rel_weight REAL,
        path TEXT[]
    ) AS $$
    BEGIN
        RETURN QUERY
        WITH RECURSIVE graph_traversal AS (
            -- Base case: Find starting entity
            SELECT
                0 AS depth,
                kv.entity_key,
                kv.entity_type,
                kv.entity_id,
                NULL::VARCHAR(100) AS rel_type,
                NULL::REAL AS rel_weight,
                ARRAY[kv.entity_key]::TEXT[] AS path
            FROM kv_store kv
            WHERE kv.tenant_id = p_tenant_id
            AND kv.entity_key = p_entity_key
            AND (p_user_id IS NULL OR kv.user_id = p_user_id OR kv.user_id IS NULL)
    
            UNION ALL
    
            -- Recursive case: Follow outbound edges from discovered entities
            SELECT
                gt.depth + 1,
                target_kv.entity_key,
                target_kv.entity_type,
                target_kv.entity_id,
                (edge->>'type')::VARCHAR(100) AS rel_type,
                COALESCE((edge->'metadata'->>'weight')::REAL, 1.0) AS rel_weight,
                gt.path || target_kv.entity_key AS path
            FROM graph_traversal gt
            -- Join to primary table to get graph_edges JSONB
            JOIN kv_store source_kv ON source_kv.entity_key = gt.entity_key
                AND source_kv.tenant_id = p_tenant_id
            JOIN resources r ON r.id = source_kv.entity_id
            -- Extract edges from JSONB array
            CROSS JOIN LATERAL jsonb_array_elements(COALESCE(r.graph_edges, '[]'::jsonb)) AS edge
            -- Lookup target entity in KV store
            JOIN kv_store target_kv ON target_kv.entity_key = (edge->>'target')::VARCHAR(255)
                AND target_kv.tenant_id = p_tenant_id
            WHERE gt.depth < p_max_depth
            -- Filter by relationship type if specified
            AND (p_rel_type IS NULL OR (edge->>'type')::VARCHAR(100) = p_rel_type)
            -- Prevent cycles by checking path
            AND NOT (target_kv.entity_key = ANY(gt.path))
            AND (p_user_id IS NULL OR target_kv.user_id = p_user_id OR target_kv.user_id IS NULL)
        )
        SELECT DISTINCT ON (entity_key)
            gt.depth,
            gt.entity_key,
            gt.entity_type,
            gt.entity_id,
            gt.rel_type,
            gt.rel_weight,
            gt.path
        FROM graph_traversal gt
        WHERE gt.depth > 0  -- Exclude starting entity
        ORDER BY gt.entity_key, gt.depth;
    END;
    $$ LANGUAGE plpgsql STABLE;
    
    COMMENT ON FUNCTION rem_traverse IS
    'REM TRAVERSE query: Recursive graph traversal following entity relationships via graph_edges';
    
    -- REM SEARCH: Vector similarity search using embeddings
    -- Joins to embeddings table for semantic search
    CREATE OR REPLACE FUNCTION rem_search(
        p_query_embedding vector(1536),
        p_table_name VARCHAR(100),
        p_field_name VARCHAR(100),
        p_tenant_id VARCHAR(100),
        p_provider VARCHAR(50) DEFAULT 'openai',
        p_min_similarity REAL DEFAULT 0.7,
        p_limit INTEGER DEFAULT 10,
        p_user_id VARCHAR(100) DEFAULT NULL
    )
    RETURNS TABLE(
        entity_key VARCHAR(255),
        entity_type VARCHAR(100),
        entity_id UUID,
        distance REAL,
        content_summary TEXT
    ) AS $$
    DECLARE
        embeddings_table VARCHAR(200);
        query_sql TEXT;
    BEGIN
        -- Construct embeddings table name
        embeddings_table := 'embeddings_' || p_table_name;
    
        -- Dynamic query to join KV_STORE with embeddings table
        -- Note: Using inner product for OpenAI embeddings (normalized vectors)
        -- Inner product <#> returns negative value, so we negate it to get [0, 1]
        -- where 1 = perfect match, 0 = orthogonal. We then compute (1 - inner_product)
        -- to get distance where 0 = perfect match, 1 = completely different
        query_sql := format('
            SELECT
                kv.entity_key,
                kv.entity_type,
                kv.entity_id,
                (1.0 - (e.embedding <#> $1) * -1.0)::REAL AS distance,
                kv.content_summary
            FROM kv_store kv
            JOIN %I e ON e.entity_id = kv.entity_id
            WHERE kv.tenant_id = $2
            AND e.field_name = $3
            AND e.provider = $4
            AND (1.0 - (e.embedding <#> $1) * -1.0) <= (1.0 - $5)
            AND ($6::VARCHAR(100) IS NULL OR kv.user_id = $6 OR kv.user_id IS NULL)
            ORDER BY e.embedding <#> $1 DESC
            LIMIT $7
        ', embeddings_table);
    
        RETURN QUERY EXECUTE query_sql
        USING p_query_embedding, p_tenant_id, p_field_name, p_provider, p_min_similarity, p_user_id, p_limit;
    END;
    $$ LANGUAGE plpgsql STABLE;
    
    COMMENT ON FUNCTION rem_search IS
    'REM SEARCH query: Vector similarity search using inner product for OpenAI normalized embeddings (0=different, 1=identical)';
    
    -- Function to get migration status
    CREATE OR REPLACE FUNCTION migration_status()
    RETURNS TABLE(
        migration_type TEXT,
        count BIGINT,
        last_applied TIMESTAMP,
        total_execution_ms BIGINT
    ) AS $$
    BEGIN
        RETURN QUERY
        SELECT
            type::TEXT,
            COUNT(*)::BIGINT,
            MAX(applied_at),
            SUM(execution_time_ms)::BIGINT
        FROM rem_migrations
        WHERE success = TRUE
        GROUP BY type
        ORDER BY MAX(applied_at) DESC;
    END;
    $$ LANGUAGE plpgsql;
    
    COMMENT ON FUNCTION migration_status() IS
    'Get summary of applied migrations by type';
    
    -- ============================================================================
    -- RECORD INSTALLATION
    -- ============================================================================
    
    INSERT INTO rem_migrations (name, type, version)
    VALUES ('install.sql', 'install', '1.0.0')
    ON CONFLICT (name) DO UPDATE
    SET applied_at = CURRENT_TIMESTAMP,
        applied_by = CURRENT_USER;
    
    -- ============================================================================
    -- COMPLETION
    -- ============================================================================
    
    DO $$
    BEGIN
        RAISE NOTICE '============================================================';
        RAISE NOTICE 'REM Database Installation Complete';
        RAISE NOTICE '============================================================';
        RAISE NOTICE '';
        RAISE NOTICE 'Extensions installed:';
        RAISE NOTICE '  ✓ pgvector (vector embeddings)';
        RAISE NOTICE '  ✓ pg_trgm (fuzzy text search)';
        RAISE NOTICE '  ✓ uuid-ossp (UUID generation)';
        RAISE NOTICE '';
        RAISE NOTICE 'Infrastructure created:';
        RAISE NOTICE '  ✓ rem_migrations (migration tracking)';
        RAISE NOTICE '  ✓ kv_store (UNLOGGED entity cache)';
        RAISE NOTICE '  ✓ Helper functions';
        RAISE NOTICE '';
        RAISE NOTICE 'Next steps:';
        RAISE NOTICE '  1. Generate model schema: rem schema generate --models src/rem/models/entities';
        RAISE NOTICE '  2. Apply model schema: rem db migrate';
        RAISE NOTICE '';
        RAISE NOTICE 'Status: SELECT * FROM migration_status();';
        RAISE NOTICE '============================================================';
    END $$;

  002_install_models.sql: |
    -- REM Model Schema (install_models.sql)
    -- Generated from Pydantic models
    -- Source directory: src/rem/models/entities
    -- Generated at: 2025-11-18T22:29:28.066745
    --
    -- DO NOT EDIT MANUALLY - Regenerate with: rem schema generate
    --
    -- This script creates:
    -- 1. Primary entity tables
    -- 2. Embeddings tables (embeddings_<table>)
    -- 3. KV_STORE triggers for cache maintenance
    -- 4. Indexes (foreground only, background indexes separate)
    
    -- ============================================================================
    -- PREREQUISITES CHECK
    -- ============================================================================
    
    DO $$
    BEGIN
        -- Check that install.sql has been run
        IF NOT EXISTS (SELECT 1 FROM pg_tables WHERE tablename = 'kv_store') THEN
            RAISE EXCEPTION 'KV_STORE table not found. Run sql/install.sql first.';
        END IF;
    
        IF NOT EXISTS (SELECT 1 FROM pg_extension WHERE extname = 'vector') THEN
            RAISE EXCEPTION 'pgvector extension not found. Run sql/install.sql first.';
        END IF;
    
        RAISE NOTICE 'Prerequisites check passed';
    END $$;
    
    -- ======================================================================
    -- USERS (Model: User)
    -- ======================================================================
    
    CREATE TABLE IF NOT EXISTS users (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        tenant_id VARCHAR(100) NOT NULL,
        user_id VARCHAR(256),
        name VARCHAR(256) NOT NULL,
        email VARCHAR(256),
        role VARCHAR(256),
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        deleted_at TIMESTAMP,
        graph_edges JSONB DEFAULT '[]'::jsonb,
        metadata JSONB DEFAULT '{}'::jsonb
    );
    
    CREATE INDEX idx_users_tenant ON users (tenant_id);
    CREATE INDEX idx_users_user ON users (user_id);
    CREATE INDEX idx_users_graph_edges ON users USING GIN (graph_edges);
    CREATE INDEX idx_users_metadata ON users USING GIN (metadata);
    
    -- KV_STORE trigger for users
    -- Trigger function to maintain KV_STORE for users
    CREATE OR REPLACE FUNCTION fn_users_kv_store_upsert()
    RETURNS TRIGGER AS $$
    BEGIN
        IF (TG_OP = 'DELETE') THEN
            -- Remove from KV_STORE on delete
            DELETE FROM kv_store
            WHERE entity_id = OLD.id;
            RETURN OLD;
        ELSIF (TG_OP = 'INSERT' OR TG_OP = 'UPDATE') THEN
            -- Upsert to KV_STORE
            INSERT INTO kv_store (
                entity_key,
                entity_type,
                entity_id,
                tenant_id,
                user_id,
                content_summary,
                metadata,
                updated_at
            ) VALUES (
                NEW.name,
                'users',
                NEW.id,
                NEW.tenant_id,
                NEW.user_id,
                COALESCE(NEW.content, ''),
                NEW.metadata,
                CURRENT_TIMESTAMP
            )
            ON CONFLICT (tenant_id, entity_key)
            DO UPDATE SET
                entity_id = EXCLUDED.entity_id,
                user_id = EXCLUDED.user_id,
                content_summary = EXCLUDED.content_summary,
                metadata = EXCLUDED.metadata,
                updated_at = CURRENT_TIMESTAMP;
    
            RETURN NEW;
        END IF;
    END;
    $$ LANGUAGE plpgsql;
    
    -- Create trigger
    DROP TRIGGER IF EXISTS trg_users_kv_store ON users;
    CREATE TRIGGER trg_users_kv_store
    AFTER INSERT OR UPDATE OR DELETE ON users
    FOR EACH ROW EXECUTE FUNCTION fn_users_kv_store_upsert();
    
    -- ======================================================================
    -- MOMENTS (Model: Moment)
    -- ======================================================================
    
    CREATE TABLE IF NOT EXISTS moments (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        tenant_id VARCHAR(100) NOT NULL,
        user_id VARCHAR(256),
        name VARCHAR(256) NOT NULL,
        moment_type VARCHAR(256),
        category VARCHAR(256),
        starts_timestamp TIMESTAMP NOT NULL,
        ends_timestamp TIMESTAMP,
        present_persons JSONB DEFAULT '{}'::jsonb,
        emotion_tags TEXT[] DEFAULT ARRAY[]::TEXT[],
        topic_tags TEXT[] DEFAULT ARRAY[]::TEXT[],
        summary TEXT,
        source_resource_ids TEXT[] DEFAULT ARRAY[]::TEXT[],
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        deleted_at TIMESTAMP,
        graph_edges JSONB DEFAULT '[]'::jsonb,
        metadata JSONB DEFAULT '{}'::jsonb
    );
    
    CREATE INDEX idx_moments_tenant ON moments (tenant_id);
    CREATE INDEX idx_moments_user ON moments (user_id);
    CREATE INDEX idx_moments_graph_edges ON moments USING GIN (graph_edges);
    CREATE INDEX idx_moments_metadata ON moments USING GIN (metadata);
    
    -- Embeddings for moments
    CREATE TABLE IF NOT EXISTS embeddings_moments (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        entity_id UUID NOT NULL REFERENCES moments(id) ON DELETE CASCADE,
        field_name VARCHAR(100) NOT NULL,
        provider VARCHAR(50) NOT NULL DEFAULT 'openai',
        model VARCHAR(100) NOT NULL DEFAULT 'text-embedding-3-small',
        embedding vector(1536) NOT NULL,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
        -- Unique: one embedding per entity per field per provider
        UNIQUE (entity_id, field_name, provider)
    );
    
    -- Index for entity lookup (get all embeddings for entity)
    CREATE INDEX idx_embeddings_moments_entity ON embeddings_moments (entity_id);
    
    -- Index for field + provider lookup
    CREATE INDEX idx_embeddings_moments_field_provider ON embeddings_moments (field_name, provider);
    
    -- HNSW index for vector similarity search (created in background)
    -- Note: This will be created by background thread after data load
    -- CREATE INDEX idx_embeddings_moments_vector_hnsw ON embeddings_moments
    -- USING hnsw (embedding vector_cosine_ops);
    
    -- KV_STORE trigger for moments
    -- Trigger function to maintain KV_STORE for moments
    CREATE OR REPLACE FUNCTION fn_moments_kv_store_upsert()
    RETURNS TRIGGER AS $$
    BEGIN
        IF (TG_OP = 'DELETE') THEN
            -- Remove from KV_STORE on delete
            DELETE FROM kv_store
            WHERE entity_id = OLD.id;
            RETURN OLD;
        ELSIF (TG_OP = 'INSERT' OR TG_OP = 'UPDATE') THEN
            -- Upsert to KV_STORE
            INSERT INTO kv_store (
                entity_key,
                entity_type,
                entity_id,
                tenant_id,
                user_id,
                content_summary,
                metadata,
                updated_at
            ) VALUES (
                NEW.name,
                'moments',
                NEW.id,
                NEW.tenant_id,
                NEW.user_id,
                COALESCE(NEW.content, ''),
                NEW.metadata,
                CURRENT_TIMESTAMP
            )
            ON CONFLICT (tenant_id, entity_key)
            DO UPDATE SET
                entity_id = EXCLUDED.entity_id,
                user_id = EXCLUDED.user_id,
                content_summary = EXCLUDED.content_summary,
                metadata = EXCLUDED.metadata,
                updated_at = CURRENT_TIMESTAMP;
    
            RETURN NEW;
        END IF;
    END;
    $$ LANGUAGE plpgsql;
    
    -- Create trigger
    DROP TRIGGER IF EXISTS trg_moments_kv_store ON moments;
    CREATE TRIGGER trg_moments_kv_store
    AFTER INSERT OR UPDATE OR DELETE ON moments
    FOR EACH ROW EXECUTE FUNCTION fn_moments_kv_store_upsert();
    
    -- ======================================================================
    -- PERSONS (Model: Person)
    -- ======================================================================
    
    CREATE TABLE IF NOT EXISTS persons (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        tenant_id VARCHAR(100) NOT NULL,
        user_id VARCHAR(256),
        name VARCHAR(256) NOT NULL,
        role VARCHAR(256),
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        deleted_at TIMESTAMP,
        graph_edges JSONB DEFAULT '[]'::jsonb,
        metadata JSONB DEFAULT '{}'::jsonb
    );
    
    CREATE INDEX idx_persons_tenant ON persons (tenant_id);
    CREATE INDEX idx_persons_user ON persons (user_id);
    CREATE INDEX idx_persons_graph_edges ON persons USING GIN (graph_edges);
    CREATE INDEX idx_persons_metadata ON persons USING GIN (metadata);
    
    -- KV_STORE trigger for persons
    -- Trigger function to maintain KV_STORE for persons
    CREATE OR REPLACE FUNCTION fn_persons_kv_store_upsert()
    RETURNS TRIGGER AS $$
    BEGIN
        IF (TG_OP = 'DELETE') THEN
            -- Remove from KV_STORE on delete
            DELETE FROM kv_store
            WHERE entity_id = OLD.id;
            RETURN OLD;
        ELSIF (TG_OP = 'INSERT' OR TG_OP = 'UPDATE') THEN
            -- Upsert to KV_STORE
            INSERT INTO kv_store (
                entity_key,
                entity_type,
                entity_id,
                tenant_id,
                user_id,
                content_summary,
                metadata,
                updated_at
            ) VALUES (
                NEW.name,
                'persons',
                NEW.id,
                NEW.tenant_id,
                NEW.user_id,
                COALESCE(NEW.content, ''),
                NEW.metadata,
                CURRENT_TIMESTAMP
            )
            ON CONFLICT (tenant_id, entity_key)
            DO UPDATE SET
                entity_id = EXCLUDED.entity_id,
                user_id = EXCLUDED.user_id,
                content_summary = EXCLUDED.content_summary,
                metadata = EXCLUDED.metadata,
                updated_at = CURRENT_TIMESTAMP;
    
            RETURN NEW;
        END IF;
    END;
    $$ LANGUAGE plpgsql;
    
    -- Create trigger
    DROP TRIGGER IF EXISTS trg_persons_kv_store ON persons;
    CREATE TRIGGER trg_persons_kv_store
    AFTER INSERT OR UPDATE OR DELETE ON persons
    FOR EACH ROW EXECUTE FUNCTION fn_persons_kv_store_upsert();
    
    -- ======================================================================
    -- RESOURCES (Model: Resource)
    -- ======================================================================
    
    CREATE TABLE IF NOT EXISTS resources (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        tenant_id VARCHAR(100) NOT NULL,
        user_id VARCHAR(256),
        name VARCHAR(256) NOT NULL,
        uri VARCHAR(256),
        ordinal INTEGER,
        content TEXT,
        timestamp TIMESTAMP,
        category VARCHAR(256),
        related_entities JSONB DEFAULT '{}'::jsonb,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        deleted_at TIMESTAMP,
        graph_edges JSONB DEFAULT '[]'::jsonb,
        metadata JSONB DEFAULT '{}'::jsonb
    );
    
    CREATE INDEX idx_resources_tenant ON resources (tenant_id);
    CREATE INDEX idx_resources_user ON resources (user_id);
    CREATE INDEX idx_resources_graph_edges ON resources USING GIN (graph_edges);
    CREATE INDEX idx_resources_metadata ON resources USING GIN (metadata);
    
    -- Embeddings for resources
    CREATE TABLE IF NOT EXISTS embeddings_resources (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        entity_id UUID NOT NULL REFERENCES resources(id) ON DELETE CASCADE,
        field_name VARCHAR(100) NOT NULL,
        provider VARCHAR(50) NOT NULL DEFAULT 'openai',
        model VARCHAR(100) NOT NULL DEFAULT 'text-embedding-3-small',
        embedding vector(1536) NOT NULL,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
        -- Unique: one embedding per entity per field per provider
        UNIQUE (entity_id, field_name, provider)
    );
    
    -- Index for entity lookup (get all embeddings for entity)
    CREATE INDEX idx_embeddings_resources_entity ON embeddings_resources (entity_id);
    
    -- Index for field + provider lookup
    CREATE INDEX idx_embeddings_resources_field_provider ON embeddings_resources (field_name, provider);
    
    -- HNSW index for vector similarity search (created in background)
    -- Note: This will be created by background thread after data load
    -- CREATE INDEX idx_embeddings_resources_vector_hnsw ON embeddings_resources
    -- USING hnsw (embedding vector_cosine_ops);
    
    -- KV_STORE trigger for resources
    -- Trigger function to maintain KV_STORE for resources
    CREATE OR REPLACE FUNCTION fn_resources_kv_store_upsert()
    RETURNS TRIGGER AS $$
    BEGIN
        IF (TG_OP = 'DELETE') THEN
            -- Remove from KV_STORE on delete
            DELETE FROM kv_store
            WHERE entity_id = OLD.id;
            RETURN OLD;
        ELSIF (TG_OP = 'INSERT' OR TG_OP = 'UPDATE') THEN
            -- Upsert to KV_STORE
            INSERT INTO kv_store (
                entity_key,
                entity_type,
                entity_id,
                tenant_id,
                user_id,
                content_summary,
                metadata,
                updated_at
            ) VALUES (
                NEW.uri,
                'resources',
                NEW.id,
                NEW.tenant_id,
                NEW.user_id,
                COALESCE(NEW.content, ''),
                NEW.metadata,
                CURRENT_TIMESTAMP
            )
            ON CONFLICT (tenant_id, entity_key)
            DO UPDATE SET
                entity_id = EXCLUDED.entity_id,
                user_id = EXCLUDED.user_id,
                content_summary = EXCLUDED.content_summary,
                metadata = EXCLUDED.metadata,
                updated_at = CURRENT_TIMESTAMP;
    
            RETURN NEW;
        END IF;
    END;
    $$ LANGUAGE plpgsql;
    
    -- Create trigger
    DROP TRIGGER IF EXISTS trg_resources_kv_store ON resources;
    CREATE TRIGGER trg_resources_kv_store
    AFTER INSERT OR UPDATE OR DELETE ON resources
    FOR EACH ROW EXECUTE FUNCTION fn_resources_kv_store_upsert();
    
    -- ======================================================================
    -- MESSAGES (Model: Message)
    -- ======================================================================
    
    CREATE TABLE IF NOT EXISTS messages (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        tenant_id VARCHAR(100) NOT NULL,
        user_id VARCHAR(256),
        content TEXT NOT NULL,
        message_type TEXT,
        session_id TEXT,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        deleted_at TIMESTAMP,
        graph_edges JSONB DEFAULT '[]'::jsonb,
        metadata JSONB DEFAULT '{}'::jsonb
    );
    
    CREATE INDEX idx_messages_tenant ON messages (tenant_id);
    CREATE INDEX idx_messages_user ON messages (user_id);
    CREATE INDEX idx_messages_graph_edges ON messages USING GIN (graph_edges);
    CREATE INDEX idx_messages_metadata ON messages USING GIN (metadata);
    
    -- Embeddings for messages
    CREATE TABLE IF NOT EXISTS embeddings_messages (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        entity_id UUID NOT NULL REFERENCES messages(id) ON DELETE CASCADE,
        field_name VARCHAR(100) NOT NULL,
        provider VARCHAR(50) NOT NULL DEFAULT 'openai',
        model VARCHAR(100) NOT NULL DEFAULT 'text-embedding-3-small',
        embedding vector(1536) NOT NULL,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
        -- Unique: one embedding per entity per field per provider
        UNIQUE (entity_id, field_name, provider)
    );
    
    -- Index for entity lookup (get all embeddings for entity)
    CREATE INDEX idx_embeddings_messages_entity ON embeddings_messages (entity_id);
    
    -- Index for field + provider lookup
    CREATE INDEX idx_embeddings_messages_field_provider ON embeddings_messages (field_name, provider);
    
    -- HNSW index for vector similarity search (created in background)
    -- Note: This will be created by background thread after data load
    -- CREATE INDEX idx_embeddings_messages_vector_hnsw ON embeddings_messages
    -- USING hnsw (embedding vector_cosine_ops);
    
    -- KV_STORE trigger for messages
    -- Trigger function to maintain KV_STORE for messages
    CREATE OR REPLACE FUNCTION fn_messages_kv_store_upsert()
    RETURNS TRIGGER AS $$
    BEGIN
        IF (TG_OP = 'DELETE') THEN
            -- Remove from KV_STORE on delete
            DELETE FROM kv_store
            WHERE entity_id = OLD.id;
            RETURN OLD;
        ELSIF (TG_OP = 'INSERT' OR TG_OP = 'UPDATE') THEN
            -- Upsert to KV_STORE
            INSERT INTO kv_store (
                entity_key,
                entity_type,
                entity_id,
                tenant_id,
                user_id,
                content_summary,
                metadata,
                updated_at
            ) VALUES (
                NEW.content,
                'messages',
                NEW.id,
                NEW.tenant_id,
                NEW.user_id,
                COALESCE(NEW.content, ''),
                NEW.metadata,
                CURRENT_TIMESTAMP
            )
            ON CONFLICT (tenant_id, entity_key)
            DO UPDATE SET
                entity_id = EXCLUDED.entity_id,
                user_id = EXCLUDED.user_id,
                content_summary = EXCLUDED.content_summary,
                metadata = EXCLUDED.metadata,
                updated_at = CURRENT_TIMESTAMP;
    
            RETURN NEW;
        END IF;
    END;
    $$ LANGUAGE plpgsql;
    
    -- Create trigger
    DROP TRIGGER IF EXISTS trg_messages_kv_store ON messages;
    CREATE TRIGGER trg_messages_kv_store
    AFTER INSERT OR UPDATE OR DELETE ON messages
    FOR EACH ROW EXECUTE FUNCTION fn_messages_kv_store_upsert();
    
    -- ======================================================================
    -- FILES (Model: File)
    -- ======================================================================
    
    CREATE TABLE IF NOT EXISTS files (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        tenant_id VARCHAR(100) NOT NULL,
        user_id VARCHAR(256),
        name VARCHAR(256) NOT NULL,
        uri VARCHAR(256) NOT NULL,
        content TEXT,
        timestamp VARCHAR(256),
        size_bytes INTEGER,
        mime_type VARCHAR(256),
        processing_status VARCHAR(256),
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        deleted_at TIMESTAMP,
        graph_edges JSONB DEFAULT '[]'::jsonb,
        metadata JSONB DEFAULT '{}'::jsonb
    );
    
    CREATE INDEX idx_files_tenant ON files (tenant_id);
    CREATE INDEX idx_files_user ON files (user_id);
    CREATE INDEX idx_files_graph_edges ON files USING GIN (graph_edges);
    CREATE INDEX idx_files_metadata ON files USING GIN (metadata);
    
    -- Embeddings for files
    CREATE TABLE IF NOT EXISTS embeddings_files (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        entity_id UUID NOT NULL REFERENCES files(id) ON DELETE CASCADE,
        field_name VARCHAR(100) NOT NULL,
        provider VARCHAR(50) NOT NULL DEFAULT 'openai',
        model VARCHAR(100) NOT NULL DEFAULT 'text-embedding-3-small',
        embedding vector(1536) NOT NULL,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
        -- Unique: one embedding per entity per field per provider
        UNIQUE (entity_id, field_name, provider)
    );
    
    -- Index for entity lookup (get all embeddings for entity)
    CREATE INDEX idx_embeddings_files_entity ON embeddings_files (entity_id);
    
    -- Index for field + provider lookup
    CREATE INDEX idx_embeddings_files_field_provider ON embeddings_files (field_name, provider);
    
    -- HNSW index for vector similarity search (created in background)
    -- Note: This will be created by background thread after data load
    -- CREATE INDEX idx_embeddings_files_vector_hnsw ON embeddings_files
    -- USING hnsw (embedding vector_cosine_ops);
    
    -- KV_STORE trigger for files
    -- Trigger function to maintain KV_STORE for files
    CREATE OR REPLACE FUNCTION fn_files_kv_store_upsert()
    RETURNS TRIGGER AS $$
    BEGIN
        IF (TG_OP = 'DELETE') THEN
            -- Remove from KV_STORE on delete
            DELETE FROM kv_store
            WHERE entity_id = OLD.id;
            RETURN OLD;
        ELSIF (TG_OP = 'INSERT' OR TG_OP = 'UPDATE') THEN
            -- Upsert to KV_STORE
            INSERT INTO kv_store (
                entity_key,
                entity_type,
                entity_id,
                tenant_id,
                user_id,
                content_summary,
                metadata,
                updated_at
            ) VALUES (
                NEW.name,
                'files',
                NEW.id,
                NEW.tenant_id,
                NEW.user_id,
                COALESCE(NEW.content, ''),
                NEW.metadata,
                CURRENT_TIMESTAMP
            )
            ON CONFLICT (tenant_id, entity_key)
            DO UPDATE SET
                entity_id = EXCLUDED.entity_id,
                user_id = EXCLUDED.user_id,
                content_summary = EXCLUDED.content_summary,
                metadata = EXCLUDED.metadata,
                updated_at = CURRENT_TIMESTAMP;
    
            RETURN NEW;
        END IF;
    END;
    $$ LANGUAGE plpgsql;
    
    -- Create trigger
    DROP TRIGGER IF EXISTS trg_files_kv_store ON files;
    CREATE TRIGGER trg_files_kv_store
    AFTER INSERT OR UPDATE OR DELETE ON files
    FOR EACH ROW EXECUTE FUNCTION fn_files_kv_store_upsert();
    
    -- ======================================================================
    -- SCHEMAS (Model: Schema)
    -- ======================================================================
    
    CREATE TABLE IF NOT EXISTS schemas (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        tenant_id VARCHAR(100) NOT NULL,
        user_id VARCHAR(256),
        name VARCHAR(256) NOT NULL,
        content TEXT,
        spec JSONB NOT NULL,
        category VARCHAR(256),
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        deleted_at TIMESTAMP,
        graph_edges JSONB DEFAULT '[]'::jsonb,
        metadata JSONB DEFAULT '{}'::jsonb
    );
    
    CREATE INDEX idx_schemas_tenant ON schemas (tenant_id);
    CREATE INDEX idx_schemas_user ON schemas (user_id);
    CREATE INDEX idx_schemas_graph_edges ON schemas USING GIN (graph_edges);
    CREATE INDEX idx_schemas_metadata ON schemas USING GIN (metadata);
    
    -- Embeddings for schemas
    CREATE TABLE IF NOT EXISTS embeddings_schemas (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        entity_id UUID NOT NULL REFERENCES schemas(id) ON DELETE CASCADE,
        field_name VARCHAR(100) NOT NULL,
        provider VARCHAR(50) NOT NULL DEFAULT 'openai',
        model VARCHAR(100) NOT NULL DEFAULT 'text-embedding-3-small',
        embedding vector(1536) NOT NULL,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
        -- Unique: one embedding per entity per field per provider
        UNIQUE (entity_id, field_name, provider)
    );
    
    -- Index for entity lookup (get all embeddings for entity)
    CREATE INDEX idx_embeddings_schemas_entity ON embeddings_schemas (entity_id);
    
    -- Index for field + provider lookup
    CREATE INDEX idx_embeddings_schemas_field_provider ON embeddings_schemas (field_name, provider);
    
    -- HNSW index for vector similarity search (created in background)
    -- Note: This will be created by background thread after data load
    -- CREATE INDEX idx_embeddings_schemas_vector_hnsw ON embeddings_schemas
    -- USING hnsw (embedding vector_cosine_ops);
    
    -- KV_STORE trigger for schemas
    -- Trigger function to maintain KV_STORE for schemas
    CREATE OR REPLACE FUNCTION fn_schemas_kv_store_upsert()
    RETURNS TRIGGER AS $$
    BEGIN
        IF (TG_OP = 'DELETE') THEN
            -- Remove from KV_STORE on delete
            DELETE FROM kv_store
            WHERE entity_id = OLD.id;
            RETURN OLD;
        ELSIF (TG_OP = 'INSERT' OR TG_OP = 'UPDATE') THEN
            -- Upsert to KV_STORE
            INSERT INTO kv_store (
                entity_key,
                entity_type,
                entity_id,
                tenant_id,
                user_id,
                content_summary,
                metadata,
                updated_at
            ) VALUES (
                NEW.name,
                'schemas',
                NEW.id,
                NEW.tenant_id,
                NEW.user_id,
                COALESCE(NEW.content, ''),
                NEW.metadata,
                CURRENT_TIMESTAMP
            )
            ON CONFLICT (tenant_id, entity_key)
            DO UPDATE SET
                entity_id = EXCLUDED.entity_id,
                user_id = EXCLUDED.user_id,
                content_summary = EXCLUDED.content_summary,
                metadata = EXCLUDED.metadata,
                updated_at = CURRENT_TIMESTAMP;
    
            RETURN NEW;
        END IF;
    END;
    $$ LANGUAGE plpgsql;
    
    -- Create trigger
    DROP TRIGGER IF EXISTS trg_schemas_kv_store ON schemas;
    CREATE TRIGGER trg_schemas_kv_store
    AFTER INSERT OR UPDATE OR DELETE ON schemas
    FOR EACH ROW EXECUTE FUNCTION fn_schemas_kv_store_upsert();
    
    -- ============================================================================
    -- RECORD MIGRATION
    -- ============================================================================
    
    INSERT INTO rem_migrations (name, type, version)
    VALUES ('install_models.sql', 'models', '1.0.0')
    ON CONFLICT (name) DO UPDATE
    SET applied_at = CURRENT_TIMESTAMP,
        applied_by = CURRENT_USER;
    
    DO $$
    BEGIN
        RAISE NOTICE '============================================================';
        RAISE NOTICE 'REM Model Schema Applied: 7 tables';
        RAISE NOTICE '============================================================';
        RAISE NOTICE '  ✓ files (1 embeddable fields)';
        RAISE NOTICE '  ✓ messages (1 embeddable fields)';
        RAISE NOTICE '  ✓ moments (1 embeddable fields)';
        RAISE NOTICE '  ✓ persons';
        RAISE NOTICE '  ✓ resources (1 embeddable fields)';
        RAISE NOTICE '  ✓ schemas (1 embeddable fields)';
        RAISE NOTICE '  ✓ users';
        RAISE NOTICE '';
        RAISE NOTICE 'Next: Run background indexes if needed';
        RAISE NOTICE '  rem db migrate --background-indexes';
        RAISE NOTICE '============================================================';
    END $$;
---
# Usage in postgres-cluster.yaml:
#
# spec:
#   bootstrap:
#     initdb:
#       database: remdb
#       owner: remuser
#       postInitApplicationSQLRefs:
#         configMapRefs:
#           # If multiple ConfigMaps generated, reference all in order:
#           - name: rem-postgres-init-sql
#             key: 001_install.sql
#           - name: rem-postgres-init-sql
#             key: 002_install_models.sql
#           # If split across ConfigMaps:
#           # - name: rem-postgres-init-sql-2
#           #   key: 003_large_migration.sql
#
# Notes:
# - Scripts execute in the order specified
# - Runs once during cluster bootstrap (first startup)
# - Idempotent: Uses IF NOT EXISTS, CREATE OR REPLACE, etc.
# - Errors will fail the bootstrap process
# - ConfigMap size limit: 1MB (script uses 800KB safe limit)
# - Large migrations are automatically split across multiple ConfigMaps
