# Auto-generated by: rem cluster generate
# Do not edit manually - regenerate with 'rem cluster generate'
#
# Source files:
#   - rem/sql/migrations/001_install.sql
#   - rem/sql/migrations/002_install_models.sql
#   - rem/sql/migrations/003_optional_extensions.sql
#
apiVersion: v1
kind: ConfigMap
metadata:
  name: rem-postgres-init-sql
  namespace: rem
  labels:
    app.kubernetes.io/name: rem-postgres
    app.kubernetes.io/component: init-sql
data:
  001_install.sql: "-- REM Database Installation Script\n-- Description: Core database\
    \ setup with extensions and infrastructure\n-- Version: 1.0.0\n-- Date: 2025-01-18\n\
    --\n-- This script sets up:\n-- 1. Required PostgreSQL extensions (pgvector, pg_trgm,\
    \ uuid-ossp)\n-- 2. Migration tracking table\n-- 3. KV_STORE UNLOGGED cache table\n\
    -- 4. Helper functions\n--\n-- Usage:\n--   psql -d remdb -f sql/install.sql\n\
    --\n-- Dependencies:\n--   - PostgreSQL 16+\n--   - pgvector extension compiled\
    \ and available\n--   - pg_trgm extension (usually included)\n\n-- ============================================================================\n\
    -- EXTENSIONS\n-- ============================================================================\n\
    \n-- Enable pgvector extension for vector embeddings\nCREATE EXTENSION IF NOT\
    \ EXISTS vector;\n\n-- Enable pg_trgm extension for fuzzy text search\nCREATE\
    \ EXTENSION IF NOT EXISTS pg_trgm;\n\n-- Enable uuid-ossp for UUID generation\n\
    CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";\n\n-- Verify critical extensions\n\
    DO $$\nBEGIN\n    IF NOT EXISTS (SELECT 1 FROM pg_extension WHERE extname = 'vector')\
    \ THEN\n        RAISE EXCEPTION 'pgvector extension failed to install. Ensure\
    \ pgvector is compiled and available.';\n    END IF;\n\n    IF NOT EXISTS (SELECT\
    \ 1 FROM pg_extension WHERE extname = 'pg_trgm') THEN\n        RAISE EXCEPTION\
    \ 'pg_trgm extension failed to install.';\n    END IF;\n\n    RAISE NOTICE '\u2713\
    \ All required extensions installed successfully';\nEND $$;\n\n-- ============================================================================\n\
    -- MIGRATION TRACKING\n-- ============================================================================\n\
    \nCREATE TABLE IF NOT EXISTS rem_migrations (\n    id SERIAL PRIMARY KEY,\n  \
    \  name VARCHAR(255) NOT NULL UNIQUE,\n    type VARCHAR(50) NOT NULL,  -- 'install',\
    \ 'models', 'data'\n    version VARCHAR(50),\n    checksum VARCHAR(64),\n    applied_at\
    \ TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    applied_by VARCHAR(100) DEFAULT CURRENT_USER,\n\
    \    execution_time_ms INTEGER,\n    success BOOLEAN DEFAULT TRUE\n);\n\nCREATE\
    \ INDEX IF NOT EXISTS idx_rem_migrations_type ON rem_migrations(type);\nCREATE\
    \ INDEX IF NOT EXISTS idx_rem_migrations_applied_at ON rem_migrations(applied_at);\n\
    \nCOMMENT ON TABLE rem_migrations IS\n'Tracks all applied migrations including\
    \ install scripts and model schema updates';\n\n-- ============================================================================\n\
    -- KV_STORE CACHE\n-- ============================================================================\n\
    \n-- KV_STORE: UNLOGGED table for O(1) entity lookups in REM\n--\n-- Design rationale:\n\
    -- - UNLOGGED: Faster writes, no WAL overhead (acceptable for cache)\n-- - Rebuilds\
    \ automatically from primary tables on restart\n-- - Supports LOOKUP queries with\
    \ O(1) performance\n-- - Supports FUZZY queries with trigram indexes\n-- - User-scoped\
    \ filtering when user_id IS NOT NULL\n-- - Tenant isolation via tenant_id\n--\n\
    -- Schema:\n-- - entity_key: Natural language label (e.g., \"sarah-chen\", \"\
    project-alpha\")\n-- - entity_type: Table name (e.g., \"resources\", \"moments\"\
    )\n-- - entity_id: UUID from primary table\n-- - tenant_id: Tenant identifier\
    \ for multi-tenancy\n-- - user_id: Optional user scoping (NULL = system-level)\n\
    -- - content_summary: Denormalized text for fuzzy search\n-- - metadata: JSONB\
    \ for additional filtering\n-- - updated_at: Timestamp for cache invalidation\n\
    \nCREATE UNLOGGED TABLE IF NOT EXISTS kv_store (\n    entity_key VARCHAR(255)\
    \ NOT NULL,\n    entity_type VARCHAR(100) NOT NULL,\n    entity_id UUID NOT NULL,\n\
    \    tenant_id VARCHAR(100) NOT NULL,\n    user_id VARCHAR(100),\n    content_summary\
    \ TEXT,\n    metadata JSONB DEFAULT '{}',\n    graph_edges JSONB DEFAULT '[]'::jsonb,\
    \  -- Cached edges for fast graph traversal\n    created_at TIMESTAMP DEFAULT\
    \ CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n\n\
    \    -- Composite primary key: entity_key unique per tenant\n    PRIMARY KEY (tenant_id,\
    \ entity_key)\n);\n\n-- Index for user-scoped lookups (when user_id IS NOT NULL)\n\
    CREATE INDEX IF NOT EXISTS idx_kv_store_user ON kv_store (tenant_id, user_id)\n\
    WHERE user_id IS NOT NULL;\n\n-- Index for entity_id reverse lookup (find key\
    \ by ID)\nCREATE INDEX IF NOT EXISTS idx_kv_store_entity_id ON kv_store (entity_id);\n\
    \n-- Trigram index for fuzzy text search (FUZZY queries)\nCREATE INDEX IF NOT\
    \ EXISTS idx_kv_store_key_trgm ON kv_store\nUSING gin (entity_key gin_trgm_ops);\n\
    \n-- Trigram index for content_summary fuzzy search\nCREATE INDEX IF NOT EXISTS\
    \ idx_kv_store_content_trgm ON kv_store\nUSING gin (content_summary gin_trgm_ops);\n\
    \n-- GIN index for metadata JSONB queries\nCREATE INDEX IF NOT EXISTS idx_kv_store_metadata\
    \ ON kv_store\nUSING gin (metadata);\n\n-- GIN index for graph_edges JSONB queries\
    \ (graph traversal)\nCREATE INDEX IF NOT EXISTS idx_kv_store_graph_edges ON kv_store\n\
    USING gin (graph_edges);\n\n-- Index for entity_type filtering\nCREATE INDEX IF\
    \ NOT EXISTS idx_kv_store_type ON kv_store (entity_type);\n\n-- Comments\nCOMMENT\
    \ ON TABLE kv_store IS\n'UNLOGGED cache for O(1) entity lookups. Supports REM\
    \ LOOKUP and FUZZY queries. Rebuilt from primary tables on restart.';\n\nCOMMENT\
    \ ON COLUMN kv_store.entity_key IS\n'Natural language label for entity (e.g.,\
    \ \"sarah-chen\", \"project-alpha\")';\n\nCOMMENT ON COLUMN kv_store.entity_type\
    \ IS\n'Source table name (e.g., \"resources\", \"moments\", \"users\")';\n\nCOMMENT\
    \ ON COLUMN kv_store.entity_id IS\n'UUID from primary table for reverse lookup';\n\
    \nCOMMENT ON COLUMN kv_store.tenant_id IS\n'Tenant identifier for multi-tenancy\
    \ isolation';\n\nCOMMENT ON COLUMN kv_store.user_id IS\n'Optional user scoping.\
    \ NULL = system-level entity, visible to all users in tenant';\n\nCOMMENT ON COLUMN\
    \ kv_store.content_summary IS\n'Denormalized text summary for fuzzy search. Concatenated\
    \ from content fields.';\n\n-- ============================================================================\n\
    -- HELPER FUNCTIONS\n-- ============================================================================\n\
    \n-- Function to rebuild KV_STORE from primary tables\n--\n-- IMPORTANT: You should\
    \ NOT need to call this during normal operations!\n-- KV store is automatically\
    \ populated via triggers on INSERT/UPDATE/DELETE.\n--\n-- Only call this function\
    \ after:\n--   1. Database crash/restart (UNLOGGED table lost)\n--   2. Backup\
    \ restoration (UNLOGGED tables not backed up)\n--   3. Bulk imports that bypass\
    \ triggers (COPY, pg_restore --disable-triggers)\n--\n-- Usage: SELECT * FROM\
    \ rebuild_kv_store();\nCREATE OR REPLACE FUNCTION rebuild_kv_store()\nRETURNS\
    \ TABLE(table_name TEXT, rows_inserted BIGINT) AS $$\nDECLARE\n    table_rec RECORD;\n\
    \    rows_affected BIGINT;\nBEGIN\n    -- Clear existing cache\n    DELETE FROM\
    \ kv_store;\n    RAISE NOTICE 'Cleared KV_STORE cache';\n\n    -- Rebuild from\
    \ each entity table that has a KV store trigger\n    -- This query finds all tables\
    \ with _kv_store triggers\n    FOR table_rec IN\n        SELECT DISTINCT event_object_table\
    \ as tbl\n        FROM information_schema.triggers\n        WHERE trigger_name\
    \ LIKE '%_kv_store'\n        AND trigger_schema = 'public'\n        ORDER BY event_object_table\n\
    \    LOOP\n        -- Force trigger execution by updating all non-deleted rows\n\
    \        -- This is more efficient than re-inserting\n        EXECUTE format('\n\
    \            UPDATE %I\n            SET updated_at = updated_at\n            WHERE\
    \ deleted_at IS NULL\n        ', table_rec.tbl);\n\n        GET DIAGNOSTICS rows_affected\
    \ = ROW_COUNT;\n\n        table_name := table_rec.tbl;\n        rows_inserted\
    \ := rows_affected;\n        RETURN NEXT;\n\n        RAISE NOTICE 'Rebuilt % KV\
    \ entries for %', rows_affected, table_rec.tbl;\n    END LOOP;\nEND;\n$$ LANGUAGE\
    \ plpgsql;\n\nCOMMENT ON FUNCTION rebuild_kv_store() IS\n'Rebuild KV_STORE cache\
    \ from all entity tables. Call after database restart.';\n\n-- ============================================================================\n\
    -- REM QUERY FUNCTIONS\n-- ============================================================================\n\
    \n-- REM LOOKUP: O(1) entity lookup by natural key\n-- Returns structured columns\
    \ extracted from entity records\n-- Parameters: entity_key, tenant_id (for backward\
    \ compat), user_id (actual filter)\n-- Note: tenant_id parameter exists for backward\
    \ compatibility but is ignored\n-- Note: Includes user-owned AND public (NULL\
    \ user_id) resources\nCREATE OR REPLACE FUNCTION rem_lookup(\n    p_entity_key\
    \ VARCHAR(255),\n    p_tenant_id VARCHAR(100),\n    p_user_id VARCHAR(100)\n)\n\
    RETURNS TABLE(\n    entity_type VARCHAR(100),\n    data JSONB\n) AS $$\nDECLARE\n\
    \    entity_table VARCHAR(100);\n    query_sql TEXT;\n    effective_user_id VARCHAR(100);\n\
    BEGIN\n    effective_user_id := COALESCE(p_user_id, p_tenant_id);\n\n    -- First\
    \ lookup in KV store to get entity_type (table name)\n    -- Include user-owned\
    \ AND public (NULL user_id) entries\n    SELECT kv.entity_type INTO entity_table\n\
    \    FROM kv_store kv\n    WHERE (kv.user_id = effective_user_id OR kv.user_id\
    \ IS NULL)\n    AND kv.entity_key = p_entity_key\n    LIMIT 1;\n\n    -- If not\
    \ found, return empty\n    IF entity_table IS NULL THEN\n        RETURN;\n   \
    \ END IF;\n\n    -- Fetch raw record from underlying table as JSONB\n    -- LLMs\
    \ can handle unstructured JSON - no need for schema assumptions\n    query_sql\
    \ := format('\n        SELECT\n            %L::VARCHAR(100) AS entity_type,\n\
    \            row_to_json(t)::jsonb AS data\n        FROM %I t\n        WHERE (t.user_id\
    \ = $1 OR t.user_id IS NULL)\n        AND t.name = $2\n        AND t.deleted_at\
    \ IS NULL\n    ', entity_table, entity_table);\n\n    RETURN QUERY EXECUTE query_sql\
    \ USING effective_user_id, p_entity_key;\nEND;\n$$ LANGUAGE plpgsql STABLE;\n\n\
    COMMENT ON FUNCTION rem_lookup IS\n'REM LOOKUP: O(1) entity lookup. Returns user-owned\
    \ AND public (NULL user_id) entities.';\n\n-- REM FETCH: Fetch full entity records\
    \ from multiple tables\n-- Takes JSONB mapping of {table_name: [entity_keys]},\
    \ fetches all records\n-- Returns complete entity records as JSONB (not just KV\
    \ store metadata)\n-- Note: Includes user-owned AND public (NULL user_id) resources\n\
    CREATE OR REPLACE FUNCTION rem_fetch(\n    p_entities_by_table JSONB,\n    p_user_id\
    \ VARCHAR(100)\n)\nRETURNS TABLE(\n    entity_key VARCHAR(255),\n    entity_type\
    \ VARCHAR(100),\n    entity_record JSONB\n) AS $$\nDECLARE\n    table_name TEXT;\n\
    \    entity_keys JSONB;\n    query_sql TEXT;\nBEGIN\n    -- For each table in\
    \ the input JSONB\n    FOR table_name, entity_keys IN SELECT * FROM jsonb_each(p_entities_by_table)\n\
    \    LOOP\n        -- Dynamic query to fetch records from the table\n        --\
    \ Include user-owned AND public (NULL user_id)\n        query_sql := format('\n\
    \            SELECT\n                t.name::VARCHAR(255) AS entity_key,\n   \
    \             %L::VARCHAR(100) AS entity_type,\n                row_to_json(t)::jsonb\
    \ AS entity_record\n            FROM %I t\n            WHERE t.name = ANY(SELECT\
    \ jsonb_array_elements_text($1))\n            AND (t.user_id = $2 OR t.user_id\
    \ IS NULL)\n            AND t.deleted_at IS NULL\n        ', table_name, table_name);\n\
    \n        RETURN QUERY EXECUTE query_sql USING entity_keys, p_user_id;\n    END\
    \ LOOP;\nEND;\n$$ LANGUAGE plpgsql STABLE;\n\nCOMMENT ON FUNCTION rem_fetch IS\n\
    'REM FETCH: Batch fetch entities. Returns user-owned AND public (NULL user_id)\
    \ entities.';\n\n-- REM FUZZY: Fuzzy text search using pg_trgm similarity\n--\
    \ Returns raw entity data as JSONB for LLM consumption\n-- Note: Includes user-owned\
    \ AND public (NULL user_id) resources\nCREATE OR REPLACE FUNCTION rem_fuzzy(\n\
    \    p_query TEXT,\n    p_tenant_id VARCHAR(100),\n    p_threshold REAL DEFAULT\
    \ 0.3,\n    p_limit INTEGER DEFAULT 10,\n    p_user_id VARCHAR(100) DEFAULT NULL\n\
    )\nRETURNS TABLE(\n    entity_type VARCHAR(100),\n    similarity_score REAL,\n\
    \    data JSONB\n) AS $$\nDECLARE\n    kv_matches RECORD;\n    entities_by_table\
    \ JSONB := '{}'::jsonb;\n    table_keys JSONB;\n    effective_user_id VARCHAR(100);\n\
    BEGIN\n    effective_user_id := COALESCE(p_user_id, p_tenant_id);\n\n    -- Find\
    \ matching keys in KV store (user-owned AND public)\n    FOR kv_matches IN\n \
    \       SELECT\n            kv.entity_key,\n            kv.entity_type,\n    \
    \        similarity(kv.entity_key, p_query) AS sim_score\n        FROM kv_store\
    \ kv\n        WHERE (kv.user_id = effective_user_id OR kv.user_id IS NULL)\n \
    \       AND kv.entity_key % p_query  -- Trigram similarity operator\n        AND\
    \ similarity(kv.entity_key, p_query) >= p_threshold\n        ORDER BY sim_score\
    \ DESC\n        LIMIT p_limit\n    LOOP\n        -- Build JSONB mapping {table:\
    \ [keys]}\n        IF entities_by_table ? kv_matches.entity_type THEN\n      \
    \      table_keys := entities_by_table->kv_matches.entity_type;\n            entities_by_table\
    \ := jsonb_set(\n                entities_by_table,\n                ARRAY[kv_matches.entity_type],\n\
    \                table_keys || jsonb_build_array(kv_matches.entity_key)\n    \
    \        );\n        ELSE\n            entities_by_table := jsonb_set(\n     \
    \           entities_by_table,\n                ARRAY[kv_matches.entity_type],\n\
    \                jsonb_build_array(kv_matches.entity_key)\n            );\n  \
    \      END IF;\n    END LOOP;\n\n    -- Fetch full records using rem_fetch (which\
    \ now supports NULL user_id)\n    RETURN QUERY\n    SELECT\n        f.entity_type::VARCHAR(100),\n\
    \        similarity(f.entity_key, p_query) AS similarity_score,\n        f.entity_record\
    \ AS data\n    FROM rem_fetch(entities_by_table, effective_user_id) f\n    ORDER\
    \ BY similarity_score DESC;\nEND;\n$$ LANGUAGE plpgsql STABLE;\n\nCOMMENT ON FUNCTION\
    \ rem_fuzzy IS\n'REM FUZZY: Fuzzy text search. Returns user-owned AND public (NULL\
    \ user_id) entities.';\n\n-- ============================================================================\n\
    -- REM TRAVERSE (Graph Traversal)\n-- ============================================================================\n\
    \n-- REM TRAVERSE: Recursive graph traversal following edges\n-- Explores graph_edges\
    \ starting from entity_key up to max_depth\n-- Uses cached kv_store.graph_edges\
    \ for fast traversal (no polymorphic view!)\n-- When keys_only=false, automatically\
    \ fetches full entity records\n-- Note: Includes user-owned AND public (NULL user_id)\
    \ resources\nCREATE OR REPLACE FUNCTION rem_traverse(\n    p_entity_key VARCHAR(255),\n\
    \    p_tenant_id VARCHAR(100),  -- Backward compat parameter (not used for filtering)\n\
    \    p_user_id VARCHAR(100),\n    p_max_depth INTEGER DEFAULT 1,\n    p_rel_type\
    \ VARCHAR(100) DEFAULT NULL,\n    p_keys_only BOOLEAN DEFAULT FALSE\n)\nRETURNS\
    \ TABLE(\n    depth INTEGER,\n    entity_key VARCHAR(255),\n    entity_type VARCHAR(100),\n\
    \    entity_id UUID,\n    rel_type VARCHAR(100),\n    rel_weight REAL,\n    path\
    \ TEXT[],\n    entity_record JSONB\n) AS $$\nDECLARE\n    graph_keys RECORD;\n\
    \    entities_by_table JSONB := '{}'::jsonb;\n    table_keys JSONB;\n    effective_user_id\
    \ VARCHAR(100);\nBEGIN\n    effective_user_id := COALESCE(p_user_id, p_tenant_id);\n\
    \n    FOR graph_keys IN\n        WITH RECURSIVE graph_traversal AS (\n       \
    \     -- Base case: Find starting entity (user-owned OR public)\n            SELECT\n\
    \                0 AS depth,\n                kv.entity_key,\n               \
    \ kv.entity_type,\n                kv.entity_id,\n                NULL::VARCHAR(100)\
    \ AS rel_type,\n                NULL::REAL AS rel_weight,\n                ARRAY[kv.entity_key]::TEXT[]\
    \ AS path\n            FROM kv_store kv\n            WHERE (kv.user_id = effective_user_id\
    \ OR kv.user_id IS NULL)\n            AND kv.entity_key = p_entity_key\n\n   \
    \         UNION ALL\n\n            -- Recursive case: Follow outbound edges\n\
    \            SELECT\n                gt.depth + 1,\n                target_kv.entity_key,\n\
    \                target_kv.entity_type,\n                target_kv.entity_id,\n\
    \                (edge->>'rel_type')::VARCHAR(100) AS rel_type,\n            \
    \    COALESCE((edge->>'weight')::REAL, 1.0) AS rel_weight,\n                gt.path\
    \ || target_kv.entity_key AS path\n            FROM graph_traversal gt\n     \
    \       JOIN kv_store source_kv ON source_kv.entity_key = gt.entity_key\n    \
    \            AND (source_kv.user_id = effective_user_id OR source_kv.user_id IS\
    \ NULL)\n            CROSS JOIN LATERAL jsonb_array_elements(COALESCE(source_kv.graph_edges,\
    \ '[]'::jsonb)) AS edge\n            JOIN kv_store target_kv ON target_kv.entity_key\
    \ = (edge->>'dst')::VARCHAR(255)\n                AND (target_kv.user_id = effective_user_id\
    \ OR target_kv.user_id IS NULL)\n            WHERE gt.depth < p_max_depth\n  \
    \          AND (p_rel_type IS NULL OR (edge->>'rel_type')::VARCHAR(100) = p_rel_type)\n\
    \            AND NOT (target_kv.entity_key = ANY(gt.path))\n        )\n      \
    \  SELECT DISTINCT ON (entity_key)\n            gt.depth,\n            gt.entity_key,\n\
    \            gt.entity_type,\n            gt.entity_id,\n            gt.rel_type,\n\
    \            gt.rel_weight,\n            gt.path\n        FROM graph_traversal\
    \ gt\n        WHERE gt.depth > 0\n        ORDER BY gt.entity_key, gt.depth\n \
    \   LOOP\n        IF p_keys_only THEN\n            depth := graph_keys.depth;\n\
    \            entity_key := graph_keys.entity_key;\n            entity_type :=\
    \ graph_keys.entity_type;\n            entity_id := graph_keys.entity_id;\n  \
    \          rel_type := graph_keys.rel_type;\n            rel_weight := graph_keys.rel_weight;\n\
    \            path := graph_keys.path;\n            entity_record := NULL;\n  \
    \          RETURN NEXT;\n        ELSE\n            IF entities_by_table ? graph_keys.entity_type\
    \ THEN\n                table_keys := entities_by_table->graph_keys.entity_type;\n\
    \                entities_by_table := jsonb_set(\n                    entities_by_table,\n\
    \                    ARRAY[graph_keys.entity_type],\n                    table_keys\
    \ || jsonb_build_array(graph_keys.entity_key)\n                );\n          \
    \  ELSE\n                entities_by_table := jsonb_set(\n                   \
    \ entities_by_table,\n                    ARRAY[graph_keys.entity_type],\n   \
    \                 jsonb_build_array(graph_keys.entity_key)\n                );\n\
    \            END IF;\n        END IF;\n    END LOOP;\n\n    IF NOT p_keys_only\
    \ AND entities_by_table != '{}'::jsonb THEN\n        RETURN QUERY\n        SELECT\n\
    \            NULL::INTEGER AS depth,\n            f.entity_key::VARCHAR(255),\n\
    \            f.entity_type::VARCHAR(100),\n            NULL::UUID AS entity_id,\n\
    \            NULL::VARCHAR(100) AS rel_type,\n            NULL::REAL AS rel_weight,\n\
    \            NULL::TEXT[] AS path,\n            f.entity_record\n        FROM\
    \ rem_fetch(entities_by_table, effective_user_id) f;\n    END IF;\nEND;\n$$ LANGUAGE\
    \ plpgsql STABLE;\n\nCOMMENT ON FUNCTION rem_traverse IS\n'REM TRAVERSE: Graph\
    \ traversal. Returns user-owned AND public (NULL user_id) entities.';\n\n-- REM\
    \ SEARCH: Vector similarity search using embeddings\n-- Joins to embeddings table\
    \ for semantic search\n-- Note: Includes user-owned AND public (NULL user_id)\
    \ resources\nCREATE OR REPLACE FUNCTION rem_search(\n    p_query_embedding vector,\n\
    \    p_table_name VARCHAR(100),\n    p_field_name VARCHAR(100),\n    p_tenant_id\
    \ VARCHAR(100),\n    p_provider VARCHAR(50) DEFAULT 'openai',\n    p_min_similarity\
    \ REAL DEFAULT 0.7,\n    p_limit INTEGER DEFAULT 10,\n    p_user_id VARCHAR(100)\
    \ DEFAULT NULL\n)\nRETURNS TABLE(\n    entity_type VARCHAR(100),\n    similarity_score\
    \ REAL,\n    data JSONB\n) AS $$\nDECLARE\n    embeddings_table VARCHAR(200);\n\
    \    source_table VARCHAR(100);\n    query_sql TEXT;\n    effective_user_id VARCHAR(100);\n\
    BEGIN\n    embeddings_table := 'embeddings_' || p_table_name;\n    source_table\
    \ := p_table_name;\n    effective_user_id := COALESCE(p_user_id, p_tenant_id);\n\
    \n    -- Uses cosine distance <=> operator (0-2 range, 0=identical)\n    -- Similarity\
    \ = 1 - distance gives 0-1 range where 1 = most similar\n    -- Includes user-owned\
    \ AND public (NULL user_id) resources\n    query_sql := format('\n        SELECT\n\
    \            %L::VARCHAR(100) AS entity_type,\n            (1.0 - (e.embedding\
    \ <=> $1))::REAL AS similarity_score,\n            row_to_json(t)::jsonb AS data\n\
    \        FROM %I t\n        JOIN %I e ON e.entity_id = t.id\n        WHERE (t.user_id\
    \ = $2 OR t.user_id IS NULL)\n        AND e.field_name = $3\n        AND e.provider\
    \ = $4\n        AND (1.0 - (e.embedding <=> $1)) >= $5\n        AND t.deleted_at\
    \ IS NULL\n        ORDER BY e.embedding <=> $1\n        LIMIT $6\n    ', source_table,\
    \ source_table, embeddings_table);\n\n    RETURN QUERY EXECUTE query_sql\n   \
    \ USING p_query_embedding, effective_user_id, p_field_name, p_provider, p_min_similarity,\
    \ p_limit;\nEND;\n$$ LANGUAGE plpgsql STABLE;\n\nCOMMENT ON FUNCTION rem_search\
    \ IS\n'REM SEARCH: Vector similarity search. Returns user-owned AND public (NULL\
    \ user_id) resources.';\n\n-- Function to get migration status\nCREATE OR REPLACE\
    \ FUNCTION migration_status()\nRETURNS TABLE(\n    migration_type TEXT,\n    count\
    \ BIGINT,\n    last_applied TIMESTAMP,\n    total_execution_ms BIGINT\n) AS $$\n\
    BEGIN\n    RETURN QUERY\n    SELECT\n        type::TEXT,\n        COUNT(*)::BIGINT,\n\
    \        MAX(applied_at),\n        SUM(execution_time_ms)::BIGINT\n    FROM rem_migrations\n\
    \    WHERE success = TRUE\n    GROUP BY type\n    ORDER BY MAX(applied_at) DESC;\n\
    END;\n$$ LANGUAGE plpgsql;\n\nCOMMENT ON FUNCTION migration_status() IS\n'Get\
    \ summary of applied migrations by type';\n\n-- ============================================================================\n\
    -- RATE LIMITS (UNLOGGED for performance)\n-- ============================================================================\n\
    -- High-performance rate limiting table. Uses UNLOGGED for speed - counts may\n\
    -- be lost on database crash/restart, which is acceptable (fail-open on error).\n\
    \nCREATE UNLOGGED TABLE IF NOT EXISTS rate_limits (\n    key VARCHAR(512) PRIMARY\
    \ KEY,\n    count INTEGER NOT NULL DEFAULT 1,\n    expires_at TIMESTAMP NOT NULL,\n\
    \    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE INDEX IF NOT\
    \ EXISTS idx_rate_limits_expires ON rate_limits (expires_at);\n\nCOMMENT ON TABLE\
    \ rate_limits IS\n'UNLOGGED rate limiting table. Counts may be lost on crash (acceptable\
    \ for rate limiting).';\n\n-- ============================================================================\n\
    -- RECORD INSTALLATION\n-- ============================================================================\n\
    \nINSERT INTO rem_migrations (name, type, version)\nVALUES ('install.sql', 'install',\
    \ '1.0.0')\nON CONFLICT (name) DO UPDATE\nSET applied_at = CURRENT_TIMESTAMP,\n\
    \    applied_by = CURRENT_USER;\n\n-- ============================================================================\n\
    -- GRANTS FOR APPLICATION USER\n-- ============================================================================\n\
    -- Grant permissions to remuser (the application database user)\n-- This ensures\
    \ the application can run migrations and manage schema\n-- Note: remuser is created\
    \ by CNPG as the database owner in bootstrap.initdb.owner\n\nDO $$\nDECLARE\n\
    \    app_user TEXT := 'remuser';\nBEGIN\n    -- Only grant if the user exists\
    \ (handles different deployment scenarios)\n    IF EXISTS (SELECT 1 FROM pg_roles\
    \ WHERE rolname = app_user) THEN\n        -- Grant ownership of migration tracking\
    \ table so app can record migrations\n        EXECUTE format('ALTER TABLE rem_migrations\
    \ OWNER TO %I', app_user);\n        EXECUTE format('ALTER TABLE kv_store OWNER\
    \ TO %I', app_user);\n        EXECUTE format('ALTER TABLE rate_limits OWNER TO\
    \ %I', app_user);\n\n        -- Grant usage on schema\n        EXECUTE format('GRANT\
    \ ALL ON SCHEMA public TO %I', app_user);\n\n        -- Grant privileges on all\
    \ tables in public schema\n        EXECUTE format('GRANT ALL PRIVILEGES ON ALL\
    \ TABLES IN SCHEMA public TO %I', app_user);\n        EXECUTE format('GRANT ALL\
    \ PRIVILEGES ON ALL SEQUENCES IN SCHEMA public TO %I', app_user);\n        EXECUTE\
    \ format('GRANT ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA public TO %I', app_user);\n\
    \n        -- Set default privileges for future objects\n        EXECUTE format('ALTER\
    \ DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL ON TABLES TO %I', app_user);\n\
    \        EXECUTE format('ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL ON\
    \ SEQUENCES TO %I', app_user);\n        EXECUTE format('ALTER DEFAULT PRIVILEGES\
    \ IN SCHEMA public GRANT ALL ON FUNCTIONS TO %I', app_user);\n\n        RAISE\
    \ NOTICE '\u2713 Granted permissions to application user: %', app_user;\n    ELSE\n\
    \        RAISE NOTICE 'Application user % does not exist, skipping grants', app_user;\n\
    \    END IF;\nEND $$;\n\n-- ============================================================================\n\
    -- COMPLETION\n-- ============================================================================\n\
    \nDO $$\nBEGIN\n    RAISE NOTICE '============================================================';\n\
    \    RAISE NOTICE 'REM Database Installation Complete';\n    RAISE NOTICE '============================================================';\n\
    \    RAISE NOTICE '';\n    RAISE NOTICE 'Extensions installed:';\n    RAISE NOTICE\
    \ '  \u2713 pgvector (vector embeddings)';\n    RAISE NOTICE '  \u2713 pg_trgm\
    \ (fuzzy text search)';\n    RAISE NOTICE '  \u2713 uuid-ossp (UUID generation)';\n\
    \    RAISE NOTICE '';\n    RAISE NOTICE 'Infrastructure created:';\n    RAISE\
    \ NOTICE '  \u2713 rem_migrations (migration tracking)';\n    RAISE NOTICE ' \
    \ \u2713 kv_store (UNLOGGED entity cache)';\n    RAISE NOTICE '  \u2713 Helper\
    \ functions';\n    RAISE NOTICE '';\n    RAISE NOTICE 'Next steps:';\n    RAISE\
    \ NOTICE '  1. Generate model schema: rem schema generate --models src/rem/models/entities';\n\
    \    RAISE NOTICE '  2. Apply model schema: rem db migrate';\n    RAISE NOTICE\
    \ '';\n    RAISE NOTICE 'Status: SELECT * FROM migration_status();';\n    RAISE\
    \ NOTICE '============================================================';\nEND\
    \ $$;\n"
  002_install_models.sql: "-- REM Model Schema (install_models.sql)\n-- Generated\
    \ from Pydantic models\n-- Source: model registry\n-- Generated at: 2025-11-29T11:08:16.713884\n\
    --\n-- DO NOT EDIT MANUALLY - Regenerate with: rem db schema generate\n--\n--\
    \ This script creates:\n-- 1. Primary entity tables\n-- 2. Embeddings tables (embeddings_<table>)\n\
    -- 3. KV_STORE triggers for cache maintenance\n-- 4. Indexes (foreground only,\
    \ background indexes separate)\n\n-- ============================================================================\n\
    -- PREREQUISITES CHECK\n-- ============================================================================\n\
    \nDO $$\nBEGIN\n    -- Check that install.sql has been run\n    IF NOT EXISTS\
    \ (SELECT 1 FROM pg_tables WHERE tablename = 'kv_store') THEN\n        RAISE EXCEPTION\
    \ 'KV_STORE table not found. Run migrations/001_install.sql first.';\n    END\
    \ IF;\n\n    IF NOT EXISTS (SELECT 1 FROM pg_extension WHERE extname = 'vector')\
    \ THEN\n        RAISE EXCEPTION 'pgvector extension not found. Run migrations/001_install.sql\
    \ first.';\n    END IF;\n\n    RAISE NOTICE 'Prerequisites check passed';\nEND\
    \ $$;\n\n-- ======================================================================\n\
    -- FEEDBACKS (Model: Feedback)\n-- ======================================================================\n\
    \nCREATE TABLE IF NOT EXISTS feedbacks (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n\
    \    tenant_id VARCHAR(100) NOT NULL,\n    user_id VARCHAR(256),\n    session_id\
    \ VARCHAR(256) NOT NULL,\n    message_id VARCHAR(256),\n    rating INTEGER,\n\
    \    categories TEXT[] DEFAULT ARRAY[]::TEXT[],\n    comment TEXT,\n    trace_id\
    \ VARCHAR(256),\n    span_id VARCHAR(256),\n    phoenix_synced BOOLEAN,\n    phoenix_annotation_id\
    \ VARCHAR(256),\n    annotator_kind VARCHAR(256),\n    created_at TIMESTAMP DEFAULT\
    \ CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n  \
    \  deleted_at TIMESTAMP,\n    graph_edges JSONB DEFAULT '[]'::jsonb,\n    metadata\
    \ JSONB DEFAULT '{}'::jsonb,\n    tags TEXT[] DEFAULT ARRAY[]::TEXT[]\n);\n\n\
    CREATE INDEX idx_feedbacks_tenant ON feedbacks (tenant_id);\nCREATE INDEX idx_feedbacks_user\
    \ ON feedbacks (user_id);\nCREATE INDEX idx_feedbacks_graph_edges ON feedbacks\
    \ USING GIN (graph_edges);\nCREATE INDEX idx_feedbacks_metadata ON feedbacks USING\
    \ GIN (metadata);\nCREATE INDEX idx_feedbacks_tags ON feedbacks USING GIN (tags);\n\
    \n-- KV_STORE trigger for feedbacks\n-- Trigger function to maintain KV_STORE\
    \ for feedbacks\nCREATE OR REPLACE FUNCTION fn_feedbacks_kv_store_upsert()\nRETURNS\
    \ TRIGGER AS $$\nBEGIN\n    IF (TG_OP = 'DELETE') THEN\n        -- Remove from\
    \ KV_STORE on delete\n        DELETE FROM kv_store\n        WHERE entity_id =\
    \ OLD.id;\n        RETURN OLD;\n    ELSIF (TG_OP = 'INSERT' OR TG_OP = 'UPDATE')\
    \ THEN\n        -- Upsert to KV_STORE (O(1) lookup by entity_key)\n        INSERT\
    \ INTO kv_store (\n            entity_key,\n            entity_type,\n       \
    \     entity_id,\n            tenant_id,\n            user_id,\n            metadata,\n\
    \            graph_edges,\n            updated_at\n        ) VALUES (\n      \
    \      NEW.id::VARCHAR,\n            'feedbacks',\n            NEW.id,\n     \
    \       NEW.tenant_id,\n            NEW.user_id,\n            NEW.metadata,\n\
    \            COALESCE(NEW.graph_edges, '[]'::jsonb),\n            CURRENT_TIMESTAMP\n\
    \        )\n        ON CONFLICT (tenant_id, entity_key)\n        DO UPDATE SET\n\
    \            entity_id = EXCLUDED.entity_id,\n            user_id = EXCLUDED.user_id,\n\
    \            metadata = EXCLUDED.metadata,\n            graph_edges = EXCLUDED.graph_edges,\n\
    \            updated_at = CURRENT_TIMESTAMP;\n\n        RETURN NEW;\n    END IF;\n\
    END;\n$$ LANGUAGE plpgsql;\n\n-- Create trigger\nDROP TRIGGER IF EXISTS trg_feedbacks_kv_store\
    \ ON feedbacks;\nCREATE TRIGGER trg_feedbacks_kv_store\nAFTER INSERT OR UPDATE\
    \ OR DELETE ON feedbacks\nFOR EACH ROW EXECUTE FUNCTION fn_feedbacks_kv_store_upsert();\n\
    \n-- ======================================================================\n\
    -- FILES (Model: File)\n-- ======================================================================\n\
    \nCREATE TABLE IF NOT EXISTS files (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n\
    \    tenant_id VARCHAR(100) NOT NULL,\n    user_id VARCHAR(256),\n    name VARCHAR(256)\
    \ NOT NULL,\n    uri VARCHAR(256) NOT NULL,\n    content TEXT,\n    timestamp\
    \ VARCHAR(256),\n    size_bytes INTEGER,\n    mime_type VARCHAR(256),\n    processing_status\
    \ VARCHAR(256),\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    updated_at\
    \ TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    deleted_at TIMESTAMP,\n    graph_edges\
    \ JSONB DEFAULT '[]'::jsonb,\n    metadata JSONB DEFAULT '{}'::jsonb,\n    tags\
    \ TEXT[] DEFAULT ARRAY[]::TEXT[]\n);\n\nCREATE INDEX idx_files_tenant ON files\
    \ (tenant_id);\nCREATE INDEX idx_files_user ON files (user_id);\nCREATE INDEX\
    \ idx_files_graph_edges ON files USING GIN (graph_edges);\nCREATE INDEX idx_files_metadata\
    \ ON files USING GIN (metadata);\nCREATE INDEX idx_files_tags ON files USING GIN\
    \ (tags);\n\n-- Embeddings for files\nCREATE TABLE IF NOT EXISTS embeddings_files\
    \ (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    entity_id UUID NOT\
    \ NULL REFERENCES files(id) ON DELETE CASCADE,\n    field_name VARCHAR(100) NOT\
    \ NULL,\n    provider VARCHAR(50) NOT NULL DEFAULT 'openai',\n    model VARCHAR(100)\
    \ NOT NULL DEFAULT 'text-embedding-3-small',\n    embedding vector(1536) NOT NULL,\n\
    \    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP\
    \ DEFAULT CURRENT_TIMESTAMP,\n\n    -- Unique: one embedding per entity per field\
    \ per provider\n    UNIQUE (entity_id, field_name, provider)\n);\n\n-- Index for\
    \ entity lookup (get all embeddings for entity)\nCREATE INDEX idx_embeddings_files_entity\
    \ ON embeddings_files (entity_id);\n\n-- Index for field + provider lookup\nCREATE\
    \ INDEX idx_embeddings_files_field_provider ON embeddings_files (field_name, provider);\n\
    \n-- HNSW index for vector similarity search (created in background)\n-- Note:\
    \ This will be created by background thread after data load\n-- CREATE INDEX idx_embeddings_files_vector_hnsw\
    \ ON embeddings_files\n-- USING hnsw (embedding vector_cosine_ops);\n\n-- KV_STORE\
    \ trigger for files\n-- Trigger function to maintain KV_STORE for files\nCREATE\
    \ OR REPLACE FUNCTION fn_files_kv_store_upsert()\nRETURNS TRIGGER AS $$\nBEGIN\n\
    \    IF (TG_OP = 'DELETE') THEN\n        -- Remove from KV_STORE on delete\n \
    \       DELETE FROM kv_store\n        WHERE entity_id = OLD.id;\n        RETURN\
    \ OLD;\n    ELSIF (TG_OP = 'INSERT' OR TG_OP = 'UPDATE') THEN\n        -- Upsert\
    \ to KV_STORE (O(1) lookup by entity_key)\n        INSERT INTO kv_store (\n  \
    \          entity_key,\n            entity_type,\n            entity_id,\n   \
    \         tenant_id,\n            user_id,\n            metadata,\n          \
    \  graph_edges,\n            updated_at\n        ) VALUES (\n            NEW.id::VARCHAR,\n\
    \            'files',\n            NEW.id,\n            NEW.tenant_id,\n     \
    \       NEW.user_id,\n            NEW.metadata,\n            COALESCE(NEW.graph_edges,\
    \ '[]'::jsonb),\n            CURRENT_TIMESTAMP\n        )\n        ON CONFLICT\
    \ (tenant_id, entity_key)\n        DO UPDATE SET\n            entity_id = EXCLUDED.entity_id,\n\
    \            user_id = EXCLUDED.user_id,\n            metadata = EXCLUDED.metadata,\n\
    \            graph_edges = EXCLUDED.graph_edges,\n            updated_at = CURRENT_TIMESTAMP;\n\
    \n        RETURN NEW;\n    END IF;\nEND;\n$$ LANGUAGE plpgsql;\n\n-- Create trigger\n\
    DROP TRIGGER IF EXISTS trg_files_kv_store ON files;\nCREATE TRIGGER trg_files_kv_store\n\
    AFTER INSERT OR UPDATE OR DELETE ON files\nFOR EACH ROW EXECUTE FUNCTION fn_files_kv_store_upsert();\n\
    \n-- ======================================================================\n\
    -- IMAGE_RESOURCES (Model: ImageResource)\n-- ======================================================================\n\
    \nCREATE TABLE IF NOT EXISTS image_resources (\n    id UUID PRIMARY KEY DEFAULT\
    \ uuid_generate_v4(),\n    tenant_id VARCHAR(100) NOT NULL,\n    user_id VARCHAR(256),\n\
    \    name VARCHAR(256),\n    uri VARCHAR(256),\n    ordinal INTEGER,\n    content\
    \ TEXT,\n    timestamp TIMESTAMP,\n    category VARCHAR(256),\n    related_entities\
    \ JSONB DEFAULT '{}'::jsonb,\n    image_width INTEGER,\n    image_height INTEGER,\n\
    \    image_format VARCHAR(256),\n    vision_description TEXT,\n    vision_provider\
    \ VARCHAR(256),\n    vision_model VARCHAR(256),\n    clip_embedding JSONB,\n \
    \   clip_dimensions INTEGER,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n\
    \    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    deleted_at TIMESTAMP,\n\
    \    graph_edges JSONB DEFAULT '[]'::jsonb,\n    metadata JSONB DEFAULT '{}'::jsonb,\n\
    \    tags TEXT[] DEFAULT ARRAY[]::TEXT[]\n);\n\nCREATE INDEX idx_image_resources_tenant\
    \ ON image_resources (tenant_id);\nCREATE INDEX idx_image_resources_user ON image_resources\
    \ (user_id);\nCREATE INDEX idx_image_resources_graph_edges ON image_resources\
    \ USING GIN (graph_edges);\nCREATE INDEX idx_image_resources_metadata ON image_resources\
    \ USING GIN (metadata);\nCREATE INDEX idx_image_resources_tags ON image_resources\
    \ USING GIN (tags);\n\n-- Embeddings for image_resources\nCREATE TABLE IF NOT\
    \ EXISTS embeddings_image_resources (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n\
    \    entity_id UUID NOT NULL REFERENCES image_resources(id) ON DELETE CASCADE,\n\
    \    field_name VARCHAR(100) NOT NULL,\n    provider VARCHAR(50) NOT NULL DEFAULT\
    \ 'openai',\n    model VARCHAR(100) NOT NULL DEFAULT 'text-embedding-3-small',\n\
    \    embedding vector(1536) NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n\
    \    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n\n    -- Unique: one embedding\
    \ per entity per field per provider\n    UNIQUE (entity_id, field_name, provider)\n\
    );\n\n-- Index for entity lookup (get all embeddings for entity)\nCREATE INDEX\
    \ idx_embeddings_image_resources_entity ON embeddings_image_resources (entity_id);\n\
    \n-- Index for field + provider lookup\nCREATE INDEX idx_embeddings_image_resources_field_provider\
    \ ON embeddings_image_resources (field_name, provider);\n\n-- HNSW index for vector\
    \ similarity search (created in background)\n-- Note: This will be created by\
    \ background thread after data load\n-- CREATE INDEX idx_embeddings_image_resources_vector_hnsw\
    \ ON embeddings_image_resources\n-- USING hnsw (embedding vector_cosine_ops);\n\
    \n-- KV_STORE trigger for image_resources\n-- Trigger function to maintain KV_STORE\
    \ for image_resources\nCREATE OR REPLACE FUNCTION fn_image_resources_kv_store_upsert()\n\
    RETURNS TRIGGER AS $$\nBEGIN\n    IF (TG_OP = 'DELETE') THEN\n        -- Remove\
    \ from KV_STORE on delete\n        DELETE FROM kv_store\n        WHERE entity_id\
    \ = OLD.id;\n        RETURN OLD;\n    ELSIF (TG_OP = 'INSERT' OR TG_OP = 'UPDATE')\
    \ THEN\n        -- Upsert to KV_STORE (O(1) lookup by entity_key)\n        INSERT\
    \ INTO kv_store (\n            entity_key,\n            entity_type,\n       \
    \     entity_id,\n            tenant_id,\n            user_id,\n            metadata,\n\
    \            graph_edges,\n            updated_at\n        ) VALUES (\n      \
    \      NEW.name::VARCHAR,\n            'image_resources',\n            NEW.id,\n\
    \            NEW.tenant_id,\n            NEW.user_id,\n            NEW.metadata,\n\
    \            COALESCE(NEW.graph_edges, '[]'::jsonb),\n            CURRENT_TIMESTAMP\n\
    \        )\n        ON CONFLICT (tenant_id, entity_key)\n        DO UPDATE SET\n\
    \            entity_id = EXCLUDED.entity_id,\n            user_id = EXCLUDED.user_id,\n\
    \            metadata = EXCLUDED.metadata,\n            graph_edges = EXCLUDED.graph_edges,\n\
    \            updated_at = CURRENT_TIMESTAMP;\n\n        RETURN NEW;\n    END IF;\n\
    END;\n$$ LANGUAGE plpgsql;\n\n-- Create trigger\nDROP TRIGGER IF EXISTS trg_image_resources_kv_store\
    \ ON image_resources;\nCREATE TRIGGER trg_image_resources_kv_store\nAFTER INSERT\
    \ OR UPDATE OR DELETE ON image_resources\nFOR EACH ROW EXECUTE FUNCTION fn_image_resources_kv_store_upsert();\n\
    \n-- ======================================================================\n\
    -- MESSAGES (Model: Message)\n-- ======================================================================\n\
    \nCREATE TABLE IF NOT EXISTS messages (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n\
    \    tenant_id VARCHAR(100) NOT NULL,\n    user_id VARCHAR(256),\n    content\
    \ TEXT NOT NULL,\n    message_type VARCHAR(256),\n    session_id VARCHAR(256),\n\
    \    prompt TEXT,\n    model VARCHAR(256),\n    token_count INTEGER,\n    trace_id\
    \ VARCHAR(256),\n    span_id VARCHAR(256),\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n\
    \    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    deleted_at TIMESTAMP,\n\
    \    graph_edges JSONB DEFAULT '[]'::jsonb,\n    metadata JSONB DEFAULT '{}'::jsonb,\n\
    \    tags TEXT[] DEFAULT ARRAY[]::TEXT[]\n);\n\nCREATE INDEX idx_messages_tenant\
    \ ON messages (tenant_id);\nCREATE INDEX idx_messages_user ON messages (user_id);\n\
    CREATE INDEX idx_messages_graph_edges ON messages USING GIN (graph_edges);\nCREATE\
    \ INDEX idx_messages_metadata ON messages USING GIN (metadata);\nCREATE INDEX\
    \ idx_messages_tags ON messages USING GIN (tags);\n\n-- Embeddings for messages\n\
    CREATE TABLE IF NOT EXISTS embeddings_messages (\n    id UUID PRIMARY KEY DEFAULT\
    \ uuid_generate_v4(),\n    entity_id UUID NOT NULL REFERENCES messages(id) ON\
    \ DELETE CASCADE,\n    field_name VARCHAR(100) NOT NULL,\n    provider VARCHAR(50)\
    \ NOT NULL DEFAULT 'openai',\n    model VARCHAR(100) NOT NULL DEFAULT 'text-embedding-3-small',\n\
    \    embedding vector(1536) NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n\
    \    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n\n    -- Unique: one embedding\
    \ per entity per field per provider\n    UNIQUE (entity_id, field_name, provider)\n\
    );\n\n-- Index for entity lookup (get all embeddings for entity)\nCREATE INDEX\
    \ idx_embeddings_messages_entity ON embeddings_messages (entity_id);\n\n-- Index\
    \ for field + provider lookup\nCREATE INDEX idx_embeddings_messages_field_provider\
    \ ON embeddings_messages (field_name, provider);\n\n-- HNSW index for vector similarity\
    \ search (created in background)\n-- Note: This will be created by background\
    \ thread after data load\n-- CREATE INDEX idx_embeddings_messages_vector_hnsw\
    \ ON embeddings_messages\n-- USING hnsw (embedding vector_cosine_ops);\n\n-- KV_STORE\
    \ trigger for messages\n-- Trigger function to maintain KV_STORE for messages\n\
    CREATE OR REPLACE FUNCTION fn_messages_kv_store_upsert()\nRETURNS TRIGGER AS $$\n\
    BEGIN\n    IF (TG_OP = 'DELETE') THEN\n        -- Remove from KV_STORE on delete\n\
    \        DELETE FROM kv_store\n        WHERE entity_id = OLD.id;\n        RETURN\
    \ OLD;\n    ELSIF (TG_OP = 'INSERT' OR TG_OP = 'UPDATE') THEN\n        -- Upsert\
    \ to KV_STORE (O(1) lookup by entity_key)\n        INSERT INTO kv_store (\n  \
    \          entity_key,\n            entity_type,\n            entity_id,\n   \
    \         tenant_id,\n            user_id,\n            metadata,\n          \
    \  graph_edges,\n            updated_at\n        ) VALUES (\n            NEW.id::VARCHAR,\n\
    \            'messages',\n            NEW.id,\n            NEW.tenant_id,\n  \
    \          NEW.user_id,\n            NEW.metadata,\n            COALESCE(NEW.graph_edges,\
    \ '[]'::jsonb),\n            CURRENT_TIMESTAMP\n        )\n        ON CONFLICT\
    \ (tenant_id, entity_key)\n        DO UPDATE SET\n            entity_id = EXCLUDED.entity_id,\n\
    \            user_id = EXCLUDED.user_id,\n            metadata = EXCLUDED.metadata,\n\
    \            graph_edges = EXCLUDED.graph_edges,\n            updated_at = CURRENT_TIMESTAMP;\n\
    \n        RETURN NEW;\n    END IF;\nEND;\n$$ LANGUAGE plpgsql;\n\n-- Create trigger\n\
    DROP TRIGGER IF EXISTS trg_messages_kv_store ON messages;\nCREATE TRIGGER trg_messages_kv_store\n\
    AFTER INSERT OR UPDATE OR DELETE ON messages\nFOR EACH ROW EXECUTE FUNCTION fn_messages_kv_store_upsert();\n\
    \n-- ======================================================================\n\
    -- MOMENTS (Model: Moment)\n-- ======================================================================\n\
    \nCREATE TABLE IF NOT EXISTS moments (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n\
    \    tenant_id VARCHAR(100) NOT NULL,\n    user_id VARCHAR(256),\n    name VARCHAR(256),\n\
    \    moment_type VARCHAR(256),\n    category VARCHAR(256),\n    starts_timestamp\
    \ TIMESTAMP NOT NULL,\n    ends_timestamp TIMESTAMP,\n    present_persons JSONB\
    \ DEFAULT '{}'::jsonb,\n    emotion_tags TEXT[] DEFAULT ARRAY[]::TEXT[],\n   \
    \ topic_tags TEXT[] DEFAULT ARRAY[]::TEXT[],\n    summary TEXT,\n    source_resource_ids\
    \ TEXT[] DEFAULT ARRAY[]::TEXT[],\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n\
    \    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    deleted_at TIMESTAMP,\n\
    \    graph_edges JSONB DEFAULT '[]'::jsonb,\n    metadata JSONB DEFAULT '{}'::jsonb,\n\
    \    tags TEXT[] DEFAULT ARRAY[]::TEXT[]\n);\n\nCREATE INDEX idx_moments_tenant\
    \ ON moments (tenant_id);\nCREATE INDEX idx_moments_user ON moments (user_id);\n\
    CREATE INDEX idx_moments_graph_edges ON moments USING GIN (graph_edges);\nCREATE\
    \ INDEX idx_moments_metadata ON moments USING GIN (metadata);\nCREATE INDEX idx_moments_tags\
    \ ON moments USING GIN (tags);\n\n-- Embeddings for moments\nCREATE TABLE IF NOT\
    \ EXISTS embeddings_moments (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n\
    \    entity_id UUID NOT NULL REFERENCES moments(id) ON DELETE CASCADE,\n    field_name\
    \ VARCHAR(100) NOT NULL,\n    provider VARCHAR(50) NOT NULL DEFAULT 'openai',\n\
    \    model VARCHAR(100) NOT NULL DEFAULT 'text-embedding-3-small',\n    embedding\
    \ vector(1536) NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n\
    \    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n\n    -- Unique: one embedding\
    \ per entity per field per provider\n    UNIQUE (entity_id, field_name, provider)\n\
    );\n\n-- Index for entity lookup (get all embeddings for entity)\nCREATE INDEX\
    \ idx_embeddings_moments_entity ON embeddings_moments (entity_id);\n\n-- Index\
    \ for field + provider lookup\nCREATE INDEX idx_embeddings_moments_field_provider\
    \ ON embeddings_moments (field_name, provider);\n\n-- HNSW index for vector similarity\
    \ search (created in background)\n-- Note: This will be created by background\
    \ thread after data load\n-- CREATE INDEX idx_embeddings_moments_vector_hnsw ON\
    \ embeddings_moments\n-- USING hnsw (embedding vector_cosine_ops);\n\n-- KV_STORE\
    \ trigger for moments\n-- Trigger function to maintain KV_STORE for moments\n\
    CREATE OR REPLACE FUNCTION fn_moments_kv_store_upsert()\nRETURNS TRIGGER AS $$\n\
    BEGIN\n    IF (TG_OP = 'DELETE') THEN\n        -- Remove from KV_STORE on delete\n\
    \        DELETE FROM kv_store\n        WHERE entity_id = OLD.id;\n        RETURN\
    \ OLD;\n    ELSIF (TG_OP = 'INSERT' OR TG_OP = 'UPDATE') THEN\n        -- Upsert\
    \ to KV_STORE (O(1) lookup by entity_key)\n        INSERT INTO kv_store (\n  \
    \          entity_key,\n            entity_type,\n            entity_id,\n   \
    \         tenant_id,\n            user_id,\n            metadata,\n          \
    \  graph_edges,\n            updated_at\n        ) VALUES (\n            NEW.name::VARCHAR,\n\
    \            'moments',\n            NEW.id,\n            NEW.tenant_id,\n   \
    \         NEW.user_id,\n            NEW.metadata,\n            COALESCE(NEW.graph_edges,\
    \ '[]'::jsonb),\n            CURRENT_TIMESTAMP\n        )\n        ON CONFLICT\
    \ (tenant_id, entity_key)\n        DO UPDATE SET\n            entity_id = EXCLUDED.entity_id,\n\
    \            user_id = EXCLUDED.user_id,\n            metadata = EXCLUDED.metadata,\n\
    \            graph_edges = EXCLUDED.graph_edges,\n            updated_at = CURRENT_TIMESTAMP;\n\
    \n        RETURN NEW;\n    END IF;\nEND;\n$$ LANGUAGE plpgsql;\n\n-- Create trigger\n\
    DROP TRIGGER IF EXISTS trg_moments_kv_store ON moments;\nCREATE TRIGGER trg_moments_kv_store\n\
    AFTER INSERT OR UPDATE OR DELETE ON moments\nFOR EACH ROW EXECUTE FUNCTION fn_moments_kv_store_upsert();\n\
    \n-- ======================================================================\n\
    -- ONTOLOGIES (Model: Ontology)\n-- ======================================================================\n\
    \nCREATE TABLE IF NOT EXISTS ontologies (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n\
    \    tenant_id VARCHAR(100) NOT NULL,\n    user_id VARCHAR(256),\n    name VARCHAR(256)\
    \ NOT NULL,\n    file_id UUID NOT NULL,\n    agent_schema_id VARCHAR(256) NOT\
    \ NULL,\n    provider_name VARCHAR(256) NOT NULL,\n    model_name VARCHAR(256)\
    \ NOT NULL,\n    extracted_data JSONB NOT NULL,\n    confidence_score DOUBLE PRECISION,\n\
    \    extraction_timestamp VARCHAR(256),\n    embedding_text TEXT,\n    created_at\
    \ TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n\
    \    deleted_at TIMESTAMP,\n    graph_edges JSONB DEFAULT '[]'::jsonb,\n    metadata\
    \ JSONB DEFAULT '{}'::jsonb,\n    tags TEXT[] DEFAULT ARRAY[]::TEXT[]\n);\n\n\
    CREATE INDEX idx_ontologies_tenant ON ontologies (tenant_id);\nCREATE INDEX idx_ontologies_user\
    \ ON ontologies (user_id);\nCREATE INDEX idx_ontologies_graph_edges ON ontologies\
    \ USING GIN (graph_edges);\nCREATE INDEX idx_ontologies_metadata ON ontologies\
    \ USING GIN (metadata);\nCREATE INDEX idx_ontologies_tags ON ontologies USING\
    \ GIN (tags);\n\n-- KV_STORE trigger for ontologies\n-- Trigger function to maintain\
    \ KV_STORE for ontologies\nCREATE OR REPLACE FUNCTION fn_ontologies_kv_store_upsert()\n\
    RETURNS TRIGGER AS $$\nBEGIN\n    IF (TG_OP = 'DELETE') THEN\n        -- Remove\
    \ from KV_STORE on delete\n        DELETE FROM kv_store\n        WHERE entity_id\
    \ = OLD.id;\n        RETURN OLD;\n    ELSIF (TG_OP = 'INSERT' OR TG_OP = 'UPDATE')\
    \ THEN\n        -- Upsert to KV_STORE (O(1) lookup by entity_key)\n        INSERT\
    \ INTO kv_store (\n            entity_key,\n            entity_type,\n       \
    \     entity_id,\n            tenant_id,\n            user_id,\n            metadata,\n\
    \            graph_edges,\n            updated_at\n        ) VALUES (\n      \
    \      NEW.id::VARCHAR,\n            'ontologies',\n            NEW.id,\n    \
    \        NEW.tenant_id,\n            NEW.user_id,\n            NEW.metadata,\n\
    \            COALESCE(NEW.graph_edges, '[]'::jsonb),\n            CURRENT_TIMESTAMP\n\
    \        )\n        ON CONFLICT (tenant_id, entity_key)\n        DO UPDATE SET\n\
    \            entity_id = EXCLUDED.entity_id,\n            user_id = EXCLUDED.user_id,\n\
    \            metadata = EXCLUDED.metadata,\n            graph_edges = EXCLUDED.graph_edges,\n\
    \            updated_at = CURRENT_TIMESTAMP;\n\n        RETURN NEW;\n    END IF;\n\
    END;\n$$ LANGUAGE plpgsql;\n\n-- Create trigger\nDROP TRIGGER IF EXISTS trg_ontologies_kv_store\
    \ ON ontologies;\nCREATE TRIGGER trg_ontologies_kv_store\nAFTER INSERT OR UPDATE\
    \ OR DELETE ON ontologies\nFOR EACH ROW EXECUTE FUNCTION fn_ontologies_kv_store_upsert();\n\
    \n-- ======================================================================\n\
    -- ONTOLOGY_CONFIGS (Model: OntologyConfig)\n-- ======================================================================\n\
    \nCREATE TABLE IF NOT EXISTS ontology_configs (\n    id UUID PRIMARY KEY DEFAULT\
    \ uuid_generate_v4(),\n    tenant_id VARCHAR(100) NOT NULL,\n    user_id VARCHAR(256),\n\
    \    name VARCHAR(256) NOT NULL,\n    agent_schema_id VARCHAR(256) NOT NULL,\n\
    \    description TEXT,\n    mime_type_pattern VARCHAR(256),\n    uri_pattern VARCHAR(256),\n\
    \    tag_filter TEXT[],\n    priority INTEGER,\n    enabled BOOLEAN,\n    provider_name\
    \ VARCHAR(256),\n    model_name VARCHAR(256),\n    created_at TIMESTAMP DEFAULT\
    \ CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n  \
    \  deleted_at TIMESTAMP,\n    graph_edges JSONB DEFAULT '[]'::jsonb,\n    metadata\
    \ JSONB DEFAULT '{}'::jsonb,\n    tags TEXT[] DEFAULT ARRAY[]::TEXT[]\n);\n\n\
    CREATE INDEX idx_ontology_configs_tenant ON ontology_configs (tenant_id);\nCREATE\
    \ INDEX idx_ontology_configs_user ON ontology_configs (user_id);\nCREATE INDEX\
    \ idx_ontology_configs_graph_edges ON ontology_configs USING GIN (graph_edges);\n\
    CREATE INDEX idx_ontology_configs_metadata ON ontology_configs USING GIN (metadata);\n\
    CREATE INDEX idx_ontology_configs_tags ON ontology_configs USING GIN (tags);\n\
    \n-- Embeddings for ontology_configs\nCREATE TABLE IF NOT EXISTS embeddings_ontology_configs\
    \ (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    entity_id UUID NOT\
    \ NULL REFERENCES ontology_configs(id) ON DELETE CASCADE,\n    field_name VARCHAR(100)\
    \ NOT NULL,\n    provider VARCHAR(50) NOT NULL DEFAULT 'openai',\n    model VARCHAR(100)\
    \ NOT NULL DEFAULT 'text-embedding-3-small',\n    embedding vector(1536) NOT NULL,\n\
    \    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP\
    \ DEFAULT CURRENT_TIMESTAMP,\n\n    -- Unique: one embedding per entity per field\
    \ per provider\n    UNIQUE (entity_id, field_name, provider)\n);\n\n-- Index for\
    \ entity lookup (get all embeddings for entity)\nCREATE INDEX idx_embeddings_ontology_configs_entity\
    \ ON embeddings_ontology_configs (entity_id);\n\n-- Index for field + provider\
    \ lookup\nCREATE INDEX idx_embeddings_ontology_configs_field_provider ON embeddings_ontology_configs\
    \ (field_name, provider);\n\n-- HNSW index for vector similarity search (created\
    \ in background)\n-- Note: This will be created by background thread after data\
    \ load\n-- CREATE INDEX idx_embeddings_ontology_configs_vector_hnsw ON embeddings_ontology_configs\n\
    -- USING hnsw (embedding vector_cosine_ops);\n\n-- KV_STORE trigger for ontology_configs\n\
    -- Trigger function to maintain KV_STORE for ontology_configs\nCREATE OR REPLACE\
    \ FUNCTION fn_ontology_configs_kv_store_upsert()\nRETURNS TRIGGER AS $$\nBEGIN\n\
    \    IF (TG_OP = 'DELETE') THEN\n        -- Remove from KV_STORE on delete\n \
    \       DELETE FROM kv_store\n        WHERE entity_id = OLD.id;\n        RETURN\
    \ OLD;\n    ELSIF (TG_OP = 'INSERT' OR TG_OP = 'UPDATE') THEN\n        -- Upsert\
    \ to KV_STORE (O(1) lookup by entity_key)\n        INSERT INTO kv_store (\n  \
    \          entity_key,\n            entity_type,\n            entity_id,\n   \
    \         tenant_id,\n            user_id,\n            metadata,\n          \
    \  graph_edges,\n            updated_at\n        ) VALUES (\n            NEW.id::VARCHAR,\n\
    \            'ontology_configs',\n            NEW.id,\n            NEW.tenant_id,\n\
    \            NEW.user_id,\n            NEW.metadata,\n            COALESCE(NEW.graph_edges,\
    \ '[]'::jsonb),\n            CURRENT_TIMESTAMP\n        )\n        ON CONFLICT\
    \ (tenant_id, entity_key)\n        DO UPDATE SET\n            entity_id = EXCLUDED.entity_id,\n\
    \            user_id = EXCLUDED.user_id,\n            metadata = EXCLUDED.metadata,\n\
    \            graph_edges = EXCLUDED.graph_edges,\n            updated_at = CURRENT_TIMESTAMP;\n\
    \n        RETURN NEW;\n    END IF;\nEND;\n$$ LANGUAGE plpgsql;\n\n-- Create trigger\n\
    DROP TRIGGER IF EXISTS trg_ontology_configs_kv_store ON ontology_configs;\nCREATE\
    \ TRIGGER trg_ontology_configs_kv_store\nAFTER INSERT OR UPDATE OR DELETE ON ontology_configs\n\
    FOR EACH ROW EXECUTE FUNCTION fn_ontology_configs_kv_store_upsert();\n\n-- ======================================================================\n\
    -- RESOURCES (Model: Resource)\n-- ======================================================================\n\
    \nCREATE TABLE IF NOT EXISTS resources (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n\
    \    tenant_id VARCHAR(100) NOT NULL,\n    user_id VARCHAR(256),\n    name VARCHAR(256),\n\
    \    uri VARCHAR(256),\n    ordinal INTEGER,\n    content TEXT,\n    timestamp\
    \ TIMESTAMP,\n    category VARCHAR(256),\n    related_entities JSONB DEFAULT '{}'::jsonb,\n\
    \    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP\
    \ DEFAULT CURRENT_TIMESTAMP,\n    deleted_at TIMESTAMP,\n    graph_edges JSONB\
    \ DEFAULT '[]'::jsonb,\n    metadata JSONB DEFAULT '{}'::jsonb,\n    tags TEXT[]\
    \ DEFAULT ARRAY[]::TEXT[]\n);\n\nCREATE INDEX idx_resources_tenant ON resources\
    \ (tenant_id);\nCREATE INDEX idx_resources_user ON resources (user_id);\nCREATE\
    \ INDEX idx_resources_graph_edges ON resources USING GIN (graph_edges);\nCREATE\
    \ INDEX idx_resources_metadata ON resources USING GIN (metadata);\nCREATE INDEX\
    \ idx_resources_tags ON resources USING GIN (tags);\n\n-- Embeddings for resources\n\
    CREATE TABLE IF NOT EXISTS embeddings_resources (\n    id UUID PRIMARY KEY DEFAULT\
    \ uuid_generate_v4(),\n    entity_id UUID NOT NULL REFERENCES resources(id) ON\
    \ DELETE CASCADE,\n    field_name VARCHAR(100) NOT NULL,\n    provider VARCHAR(50)\
    \ NOT NULL DEFAULT 'openai',\n    model VARCHAR(100) NOT NULL DEFAULT 'text-embedding-3-small',\n\
    \    embedding vector(1536) NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n\
    \    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n\n    -- Unique: one embedding\
    \ per entity per field per provider\n    UNIQUE (entity_id, field_name, provider)\n\
    );\n\n-- Index for entity lookup (get all embeddings for entity)\nCREATE INDEX\
    \ idx_embeddings_resources_entity ON embeddings_resources (entity_id);\n\n-- Index\
    \ for field + provider lookup\nCREATE INDEX idx_embeddings_resources_field_provider\
    \ ON embeddings_resources (field_name, provider);\n\n-- HNSW index for vector\
    \ similarity search (created in background)\n-- Note: This will be created by\
    \ background thread after data load\n-- CREATE INDEX idx_embeddings_resources_vector_hnsw\
    \ ON embeddings_resources\n-- USING hnsw (embedding vector_cosine_ops);\n\n--\
    \ KV_STORE trigger for resources\n-- Trigger function to maintain KV_STORE for\
    \ resources\nCREATE OR REPLACE FUNCTION fn_resources_kv_store_upsert()\nRETURNS\
    \ TRIGGER AS $$\nBEGIN\n    IF (TG_OP = 'DELETE') THEN\n        -- Remove from\
    \ KV_STORE on delete\n        DELETE FROM kv_store\n        WHERE entity_id =\
    \ OLD.id;\n        RETURN OLD;\n    ELSIF (TG_OP = 'INSERT' OR TG_OP = 'UPDATE')\
    \ THEN\n        -- Upsert to KV_STORE (O(1) lookup by entity_key)\n        INSERT\
    \ INTO kv_store (\n            entity_key,\n            entity_type,\n       \
    \     entity_id,\n            tenant_id,\n            user_id,\n            metadata,\n\
    \            graph_edges,\n            updated_at\n        ) VALUES (\n      \
    \      NEW.name::VARCHAR,\n            'resources',\n            NEW.id,\n   \
    \         NEW.tenant_id,\n            NEW.user_id,\n            NEW.metadata,\n\
    \            COALESCE(NEW.graph_edges, '[]'::jsonb),\n            CURRENT_TIMESTAMP\n\
    \        )\n        ON CONFLICT (tenant_id, entity_key)\n        DO UPDATE SET\n\
    \            entity_id = EXCLUDED.entity_id,\n            user_id = EXCLUDED.user_id,\n\
    \            metadata = EXCLUDED.metadata,\n            graph_edges = EXCLUDED.graph_edges,\n\
    \            updated_at = CURRENT_TIMESTAMP;\n\n        RETURN NEW;\n    END IF;\n\
    END;\n$$ LANGUAGE plpgsql;\n\n-- Create trigger\nDROP TRIGGER IF EXISTS trg_resources_kv_store\
    \ ON resources;\nCREATE TRIGGER trg_resources_kv_store\nAFTER INSERT OR UPDATE\
    \ OR DELETE ON resources\nFOR EACH ROW EXECUTE FUNCTION fn_resources_kv_store_upsert();\n\
    \n-- ======================================================================\n\
    -- SCHEMAS (Model: Schema)\n-- ======================================================================\n\
    \nCREATE TABLE IF NOT EXISTS schemas (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n\
    \    tenant_id VARCHAR(100) NOT NULL,\n    user_id VARCHAR(256),\n    name VARCHAR(256)\
    \ NOT NULL,\n    content TEXT,\n    spec JSONB NOT NULL,\n    category VARCHAR(256),\n\
    \    provider_configs JSONB DEFAULT '{}'::jsonb,\n    embedding_fields TEXT[]\
    \ DEFAULT ARRAY[]::TEXT[],\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n\
    \    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    deleted_at TIMESTAMP,\n\
    \    graph_edges JSONB DEFAULT '[]'::jsonb,\n    metadata JSONB DEFAULT '{}'::jsonb,\n\
    \    tags TEXT[] DEFAULT ARRAY[]::TEXT[]\n);\n\nCREATE INDEX idx_schemas_tenant\
    \ ON schemas (tenant_id);\nCREATE INDEX idx_schemas_user ON schemas (user_id);\n\
    CREATE INDEX idx_schemas_graph_edges ON schemas USING GIN (graph_edges);\nCREATE\
    \ INDEX idx_schemas_metadata ON schemas USING GIN (metadata);\nCREATE INDEX idx_schemas_tags\
    \ ON schemas USING GIN (tags);\n\n-- Embeddings for schemas\nCREATE TABLE IF NOT\
    \ EXISTS embeddings_schemas (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n\
    \    entity_id UUID NOT NULL REFERENCES schemas(id) ON DELETE CASCADE,\n    field_name\
    \ VARCHAR(100) NOT NULL,\n    provider VARCHAR(50) NOT NULL DEFAULT 'openai',\n\
    \    model VARCHAR(100) NOT NULL DEFAULT 'text-embedding-3-small',\n    embedding\
    \ vector(1536) NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n\
    \    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n\n    -- Unique: one embedding\
    \ per entity per field per provider\n    UNIQUE (entity_id, field_name, provider)\n\
    );\n\n-- Index for entity lookup (get all embeddings for entity)\nCREATE INDEX\
    \ idx_embeddings_schemas_entity ON embeddings_schemas (entity_id);\n\n-- Index\
    \ for field + provider lookup\nCREATE INDEX idx_embeddings_schemas_field_provider\
    \ ON embeddings_schemas (field_name, provider);\n\n-- HNSW index for vector similarity\
    \ search (created in background)\n-- Note: This will be created by background\
    \ thread after data load\n-- CREATE INDEX idx_embeddings_schemas_vector_hnsw ON\
    \ embeddings_schemas\n-- USING hnsw (embedding vector_cosine_ops);\n\n-- KV_STORE\
    \ trigger for schemas\n-- Trigger function to maintain KV_STORE for schemas\n\
    CREATE OR REPLACE FUNCTION fn_schemas_kv_store_upsert()\nRETURNS TRIGGER AS $$\n\
    BEGIN\n    IF (TG_OP = 'DELETE') THEN\n        -- Remove from KV_STORE on delete\n\
    \        DELETE FROM kv_store\n        WHERE entity_id = OLD.id;\n        RETURN\
    \ OLD;\n    ELSIF (TG_OP = 'INSERT' OR TG_OP = 'UPDATE') THEN\n        -- Upsert\
    \ to KV_STORE (O(1) lookup by entity_key)\n        INSERT INTO kv_store (\n  \
    \          entity_key,\n            entity_type,\n            entity_id,\n   \
    \         tenant_id,\n            user_id,\n            metadata,\n          \
    \  graph_edges,\n            updated_at\n        ) VALUES (\n            NEW.id::VARCHAR,\n\
    \            'schemas',\n            NEW.id,\n            NEW.tenant_id,\n   \
    \         NEW.user_id,\n            NEW.metadata,\n            COALESCE(NEW.graph_edges,\
    \ '[]'::jsonb),\n            CURRENT_TIMESTAMP\n        )\n        ON CONFLICT\
    \ (tenant_id, entity_key)\n        DO UPDATE SET\n            entity_id = EXCLUDED.entity_id,\n\
    \            user_id = EXCLUDED.user_id,\n            metadata = EXCLUDED.metadata,\n\
    \            graph_edges = EXCLUDED.graph_edges,\n            updated_at = CURRENT_TIMESTAMP;\n\
    \n        RETURN NEW;\n    END IF;\nEND;\n$$ LANGUAGE plpgsql;\n\n-- Create trigger\n\
    DROP TRIGGER IF EXISTS trg_schemas_kv_store ON schemas;\nCREATE TRIGGER trg_schemas_kv_store\n\
    AFTER INSERT OR UPDATE OR DELETE ON schemas\nFOR EACH ROW EXECUTE FUNCTION fn_schemas_kv_store_upsert();\n\
    \n-- ======================================================================\n\
    -- SESSIONS (Model: Session)\n-- ======================================================================\n\
    \nCREATE TABLE IF NOT EXISTS sessions (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n\
    \    tenant_id VARCHAR(100) NOT NULL,\n    user_id VARCHAR(256),\n    name VARCHAR(256)\
    \ NOT NULL,\n    mode TEXT,\n    description TEXT,\n    original_trace_id VARCHAR(256),\n\
    \    settings_overrides JSONB,\n    prompt TEXT,\n    agent_schema_uri VARCHAR(256),\n\
    \    message_count INTEGER,\n    total_tokens INTEGER,\n    created_at TIMESTAMP\
    \ DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n\
    \    deleted_at TIMESTAMP,\n    graph_edges JSONB DEFAULT '[]'::jsonb,\n    metadata\
    \ JSONB DEFAULT '{}'::jsonb,\n    tags TEXT[] DEFAULT ARRAY[]::TEXT[]\n);\n\n\
    CREATE INDEX idx_sessions_tenant ON sessions (tenant_id);\nCREATE INDEX idx_sessions_user\
    \ ON sessions (user_id);\nCREATE INDEX idx_sessions_graph_edges ON sessions USING\
    \ GIN (graph_edges);\nCREATE INDEX idx_sessions_metadata ON sessions USING GIN\
    \ (metadata);\nCREATE INDEX idx_sessions_tags ON sessions USING GIN (tags);\n\n\
    -- Embeddings for sessions\nCREATE TABLE IF NOT EXISTS embeddings_sessions (\n\
    \    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    entity_id UUID NOT NULL\
    \ REFERENCES sessions(id) ON DELETE CASCADE,\n    field_name VARCHAR(100) NOT\
    \ NULL,\n    provider VARCHAR(50) NOT NULL DEFAULT 'openai',\n    model VARCHAR(100)\
    \ NOT NULL DEFAULT 'text-embedding-3-small',\n    embedding vector(1536) NOT NULL,\n\
    \    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP\
    \ DEFAULT CURRENT_TIMESTAMP,\n\n    -- Unique: one embedding per entity per field\
    \ per provider\n    UNIQUE (entity_id, field_name, provider)\n);\n\n-- Index for\
    \ entity lookup (get all embeddings for entity)\nCREATE INDEX idx_embeddings_sessions_entity\
    \ ON embeddings_sessions (entity_id);\n\n-- Index for field + provider lookup\n\
    CREATE INDEX idx_embeddings_sessions_field_provider ON embeddings_sessions (field_name,\
    \ provider);\n\n-- HNSW index for vector similarity search (created in background)\n\
    -- Note: This will be created by background thread after data load\n-- CREATE\
    \ INDEX idx_embeddings_sessions_vector_hnsw ON embeddings_sessions\n-- USING hnsw\
    \ (embedding vector_cosine_ops);\n\n-- KV_STORE trigger for sessions\n-- Trigger\
    \ function to maintain KV_STORE for sessions\nCREATE OR REPLACE FUNCTION fn_sessions_kv_store_upsert()\n\
    RETURNS TRIGGER AS $$\nBEGIN\n    IF (TG_OP = 'DELETE') THEN\n        -- Remove\
    \ from KV_STORE on delete\n        DELETE FROM kv_store\n        WHERE entity_id\
    \ = OLD.id;\n        RETURN OLD;\n    ELSIF (TG_OP = 'INSERT' OR TG_OP = 'UPDATE')\
    \ THEN\n        -- Upsert to KV_STORE (O(1) lookup by entity_key)\n        INSERT\
    \ INTO kv_store (\n            entity_key,\n            entity_type,\n       \
    \     entity_id,\n            tenant_id,\n            user_id,\n            metadata,\n\
    \            graph_edges,\n            updated_at\n        ) VALUES (\n      \
    \      NEW.name::VARCHAR,\n            'sessions',\n            NEW.id,\n    \
    \        NEW.tenant_id,\n            NEW.user_id,\n            NEW.metadata,\n\
    \            COALESCE(NEW.graph_edges, '[]'::jsonb),\n            CURRENT_TIMESTAMP\n\
    \        )\n        ON CONFLICT (tenant_id, entity_key)\n        DO UPDATE SET\n\
    \            entity_id = EXCLUDED.entity_id,\n            user_id = EXCLUDED.user_id,\n\
    \            metadata = EXCLUDED.metadata,\n            graph_edges = EXCLUDED.graph_edges,\n\
    \            updated_at = CURRENT_TIMESTAMP;\n\n        RETURN NEW;\n    END IF;\n\
    END;\n$$ LANGUAGE plpgsql;\n\n-- Create trigger\nDROP TRIGGER IF EXISTS trg_sessions_kv_store\
    \ ON sessions;\nCREATE TRIGGER trg_sessions_kv_store\nAFTER INSERT OR UPDATE OR\
    \ DELETE ON sessions\nFOR EACH ROW EXECUTE FUNCTION fn_sessions_kv_store_upsert();\n\
    \n-- ======================================================================\n\
    -- SHARED_SESSIONS (Model: SharedSession)\n-- ======================================================================\n\
    \nCREATE TABLE IF NOT EXISTS shared_sessions (\n    id UUID PRIMARY KEY DEFAULT\
    \ uuid_generate_v4(),\n    tenant_id VARCHAR(100) NOT NULL,\n    user_id VARCHAR(256),\n\
    \    session_id VARCHAR(256) NOT NULL,\n    owner_user_id VARCHAR(256) NOT NULL,\n\
    \    shared_with_user_id VARCHAR(256) NOT NULL,\n    created_at TIMESTAMP DEFAULT\
    \ CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n  \
    \  deleted_at TIMESTAMP,\n    graph_edges JSONB DEFAULT '[]'::jsonb,\n    metadata\
    \ JSONB DEFAULT '{}'::jsonb,\n    tags TEXT[] DEFAULT ARRAY[]::TEXT[]\n);\n\n\
    CREATE INDEX idx_shared_sessions_tenant ON shared_sessions (tenant_id);\nCREATE\
    \ INDEX idx_shared_sessions_user ON shared_sessions (user_id);\nCREATE INDEX idx_shared_sessions_graph_edges\
    \ ON shared_sessions USING GIN (graph_edges);\nCREATE INDEX idx_shared_sessions_metadata\
    \ ON shared_sessions USING GIN (metadata);\nCREATE INDEX idx_shared_sessions_tags\
    \ ON shared_sessions USING GIN (tags);\n\n-- KV_STORE trigger for shared_sessions\n\
    -- Trigger function to maintain KV_STORE for shared_sessions\nCREATE OR REPLACE\
    \ FUNCTION fn_shared_sessions_kv_store_upsert()\nRETURNS TRIGGER AS $$\nBEGIN\n\
    \    IF (TG_OP = 'DELETE') THEN\n        -- Remove from KV_STORE on delete\n \
    \       DELETE FROM kv_store\n        WHERE entity_id = OLD.id;\n        RETURN\
    \ OLD;\n    ELSIF (TG_OP = 'INSERT' OR TG_OP = 'UPDATE') THEN\n        -- Upsert\
    \ to KV_STORE (O(1) lookup by entity_key)\n        INSERT INTO kv_store (\n  \
    \          entity_key,\n            entity_type,\n            entity_id,\n   \
    \         tenant_id,\n            user_id,\n            metadata,\n          \
    \  graph_edges,\n            updated_at\n        ) VALUES (\n            NEW.id::VARCHAR,\n\
    \            'shared_sessions',\n            NEW.id,\n            NEW.tenant_id,\n\
    \            NEW.user_id,\n            NEW.metadata,\n            COALESCE(NEW.graph_edges,\
    \ '[]'::jsonb),\n            CURRENT_TIMESTAMP\n        )\n        ON CONFLICT\
    \ (tenant_id, entity_key)\n        DO UPDATE SET\n            entity_id = EXCLUDED.entity_id,\n\
    \            user_id = EXCLUDED.user_id,\n            metadata = EXCLUDED.metadata,\n\
    \            graph_edges = EXCLUDED.graph_edges,\n            updated_at = CURRENT_TIMESTAMP;\n\
    \n        RETURN NEW;\n    END IF;\nEND;\n$$ LANGUAGE plpgsql;\n\n-- Create trigger\n\
    DROP TRIGGER IF EXISTS trg_shared_sessions_kv_store ON shared_sessions;\nCREATE\
    \ TRIGGER trg_shared_sessions_kv_store\nAFTER INSERT OR UPDATE OR DELETE ON shared_sessions\n\
    FOR EACH ROW EXECUTE FUNCTION fn_shared_sessions_kv_store_upsert();\n\n-- ======================================================================\n\
    -- USERS (Model: User)\n-- ======================================================================\n\
    \nCREATE TABLE IF NOT EXISTS users (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n\
    \    tenant_id VARCHAR(100) NOT NULL,\n    user_id VARCHAR(256),\n    name VARCHAR(256)\
    \ NOT NULL,\n    email VARCHAR(256),\n    role VARCHAR(256),\n    tier TEXT,\n\
    \    anonymous_ids TEXT[] DEFAULT ARRAY[]::TEXT[],\n    sec_policy JSONB DEFAULT\
    \ '{}'::jsonb,\n    summary TEXT,\n    interests TEXT[] DEFAULT ARRAY[]::TEXT[],\n\
    \    preferred_topics TEXT[] DEFAULT ARRAY[]::TEXT[],\n    activity_level VARCHAR(256),\n\
    \    last_active_at TIMESTAMP,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n\
    \    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    deleted_at TIMESTAMP,\n\
    \    graph_edges JSONB DEFAULT '[]'::jsonb,\n    metadata JSONB DEFAULT '{}'::jsonb,\n\
    \    tags TEXT[] DEFAULT ARRAY[]::TEXT[]\n);\n\nCREATE INDEX idx_users_tenant\
    \ ON users (tenant_id);\nCREATE INDEX idx_users_user ON users (user_id);\nCREATE\
    \ INDEX idx_users_graph_edges ON users USING GIN (graph_edges);\nCREATE INDEX\
    \ idx_users_metadata ON users USING GIN (metadata);\nCREATE INDEX idx_users_tags\
    \ ON users USING GIN (tags);\n\n-- Embeddings for users\nCREATE TABLE IF NOT EXISTS\
    \ embeddings_users (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  \
    \  entity_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n    field_name\
    \ VARCHAR(100) NOT NULL,\n    provider VARCHAR(50) NOT NULL DEFAULT 'openai',\n\
    \    model VARCHAR(100) NOT NULL DEFAULT 'text-embedding-3-small',\n    embedding\
    \ vector(1536) NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n\
    \    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n\n    -- Unique: one embedding\
    \ per entity per field per provider\n    UNIQUE (entity_id, field_name, provider)\n\
    );\n\n-- Index for entity lookup (get all embeddings for entity)\nCREATE INDEX\
    \ idx_embeddings_users_entity ON embeddings_users (entity_id);\n\n-- Index for\
    \ field + provider lookup\nCREATE INDEX idx_embeddings_users_field_provider ON\
    \ embeddings_users (field_name, provider);\n\n-- HNSW index for vector similarity\
    \ search (created in background)\n-- Note: This will be created by background\
    \ thread after data load\n-- CREATE INDEX idx_embeddings_users_vector_hnsw ON\
    \ embeddings_users\n-- USING hnsw (embedding vector_cosine_ops);\n\n-- KV_STORE\
    \ trigger for users\n-- Trigger function to maintain KV_STORE for users\nCREATE\
    \ OR REPLACE FUNCTION fn_users_kv_store_upsert()\nRETURNS TRIGGER AS $$\nBEGIN\n\
    \    IF (TG_OP = 'DELETE') THEN\n        -- Remove from KV_STORE on delete\n \
    \       DELETE FROM kv_store\n        WHERE entity_id = OLD.id;\n        RETURN\
    \ OLD;\n    ELSIF (TG_OP = 'INSERT' OR TG_OP = 'UPDATE') THEN\n        -- Upsert\
    \ to KV_STORE (O(1) lookup by entity_key)\n        INSERT INTO kv_store (\n  \
    \          entity_key,\n            entity_type,\n            entity_id,\n   \
    \         tenant_id,\n            user_id,\n            metadata,\n          \
    \  graph_edges,\n            updated_at\n        ) VALUES (\n            NEW.name::VARCHAR,\n\
    \            'users',\n            NEW.id,\n            NEW.tenant_id,\n     \
    \       NEW.user_id,\n            NEW.metadata,\n            COALESCE(NEW.graph_edges,\
    \ '[]'::jsonb),\n            CURRENT_TIMESTAMP\n        )\n        ON CONFLICT\
    \ (tenant_id, entity_key)\n        DO UPDATE SET\n            entity_id = EXCLUDED.entity_id,\n\
    \            user_id = EXCLUDED.user_id,\n            metadata = EXCLUDED.metadata,\n\
    \            graph_edges = EXCLUDED.graph_edges,\n            updated_at = CURRENT_TIMESTAMP;\n\
    \n        RETURN NEW;\n    END IF;\nEND;\n$$ LANGUAGE plpgsql;\n\n-- Create trigger\n\
    DROP TRIGGER IF EXISTS trg_users_kv_store ON users;\nCREATE TRIGGER trg_users_kv_store\n\
    AFTER INSERT OR UPDATE OR DELETE ON users\nFOR EACH ROW EXECUTE FUNCTION fn_users_kv_store_upsert();\n\
    \n-- ============================================================================\n\
    -- RECORD MIGRATION\n-- ============================================================================\n\
    \nINSERT INTO rem_migrations (name, type, version)\nVALUES ('install_models.sql',\
    \ 'models', '1.0.0')\nON CONFLICT (name) DO UPDATE\nSET applied_at = CURRENT_TIMESTAMP,\n\
    \    applied_by = CURRENT_USER;\n\nDO $$\nBEGIN\n    RAISE NOTICE '============================================================';\n\
    \    RAISE NOTICE 'REM Model Schema Applied: 12 tables';\n    RAISE NOTICE '============================================================';\n\
    \    RAISE NOTICE '  \u2713 feedbacks';\n    RAISE NOTICE '  \u2713 files (1 embeddable\
    \ fields)';\n    RAISE NOTICE '  \u2713 image_resources (1 embeddable fields)';\n\
    \    RAISE NOTICE '  \u2713 messages (1 embeddable fields)';\n    RAISE NOTICE\
    \ '  \u2713 moments (1 embeddable fields)';\n    RAISE NOTICE '  \u2713 ontologies';\n\
    \    RAISE NOTICE '  \u2713 ontology_configs (1 embeddable fields)';\n    RAISE\
    \ NOTICE '  \u2713 resources (1 embeddable fields)';\n    RAISE NOTICE '  \u2713\
    \ schemas (1 embeddable fields)';\n    RAISE NOTICE '  \u2713 sessions (1 embeddable\
    \ fields)';\n    RAISE NOTICE '  \u2713 shared_sessions';\n    RAISE NOTICE '\
    \  \u2713 users (1 embeddable fields)';\n    RAISE NOTICE '';\n    RAISE NOTICE\
    \ 'Next: Run background indexes if needed';\n    RAISE NOTICE '  rem db migrate\
    \ --background-indexes';\n    RAISE NOTICE '============================================================';\n\
    END $$;"
  003_optional_extensions.sql: "-- REM Optional Extensions\n-- Description: Optional\
    \ PostgreSQL extensions that enhance functionality but are not required\n-- Version:\
    \ 1.0.0\n-- Date: 2025-11-29\n--\n-- These extensions are installed with try/catch\
    \ - failures are logged but don't break the install.\n-- This allows the same\
    \ migration to work on:\n--   - Custom images with extensions baked in (percolationlabs/rem-pg:18)\n\
    --   - Standard PostgreSQL images (extensions will be skipped)\n--\n-- Extensions:\n\
    --   - pg_net: Async HTTP/HTTPS requests from triggers and functions (Supabase)\n\
    \n-- ============================================================================\n\
    -- pg_net: Async HTTP Extension\n-- ============================================================================\n\
    -- Enables PostgreSQL to make non-blocking HTTP requests from triggers and functions.\n\
    -- Requires: Custom image with pg_net compiled, shared_preload_libraries='pg_net'\n\
    --\n-- Use cases:\n--   - Webhook notifications on data changes\n--   - Async\
    \ event publishing to external APIs\n--   - Background HTTP requests from triggers\n\
    \nDO $$\nBEGIN\n    -- Attempt to create pg_net extension\n    CREATE EXTENSION\
    \ IF NOT EXISTS pg_net;\n    RAISE NOTICE '  pg_net extension installed successfully';\n\
    EXCEPTION\n    WHEN OTHERS THEN\n        RAISE NOTICE '  pg_net extension not\
    \ available (this is OK if using standard PostgreSQL image)';\n        RAISE NOTICE\
    \ '  Error: %', SQLERRM;\nEND $$;\n\n-- ============================================================================\n\
    -- pg_net Helper Functions (only created if extension exists)\n-- ============================================================================\n\
    -- Wrapper functions for common HTTP operations with sensible defaults\n\nDO $$\n\
    BEGIN\n    -- Only create helpers if pg_net is available\n    IF EXISTS (SELECT\
    \ 1 FROM pg_extension WHERE extname = 'pg_net') THEN\n\n        -- Helper: POST\
    \ JSON to a URL with standard headers\n        EXECUTE $func$\n        CREATE\
    \ OR REPLACE FUNCTION rem_http_post(\n            p_url TEXT,\n            p_body\
    \ JSONB,\n            p_headers JSONB DEFAULT '{}'::jsonb\n        )\n       \
    \ RETURNS BIGINT AS $inner$\n        DECLARE\n            merged_headers JSONB;\n\
    \            request_id BIGINT;\n        BEGIN\n            -- Merge default headers\
    \ with provided headers\n            merged_headers := '{\"Content-Type\": \"\
    application/json\"}'::jsonb || p_headers;\n\n            SELECT net.http_post(\n\
    \                url := p_url,\n                headers := merged_headers,\n \
    \               body := p_body\n            ) INTO request_id;\n\n           \
    \ RETURN request_id;\n        END;\n        $inner$ LANGUAGE plpgsql;\n      \
    \  $func$;\n\n        RAISE NOTICE '  rem_http_post helper function created';\n\
    \n        -- Helper: GET from a URL\n        EXECUTE $func$\n        CREATE OR\
    \ REPLACE FUNCTION rem_http_get(\n            p_url TEXT,\n            p_headers\
    \ JSONB DEFAULT '{}'::jsonb\n        )\n        RETURNS BIGINT AS $inner$\n  \
    \      DECLARE\n            request_id BIGINT;\n        BEGIN\n            SELECT\
    \ net.http_get(\n                url := p_url,\n                headers := p_headers\n\
    \            ) INTO request_id;\n\n            RETURN request_id;\n        END;\n\
    \        $inner$ LANGUAGE plpgsql;\n        $func$;\n\n        RAISE NOTICE '\
    \  rem_http_get helper function created';\n\n        -- ====================================================================\n\
    \        -- REM Query Function\n        -- ====================================================================\n\
    \        -- Executes REM queries via the REM API using pg_net\n        --\n  \
    \      -- Default API host: rem-api (works in K8s same namespace)\n        --\
    \ For local Docker testing: Add \"host.docker.internal rem-api\" to /etc/hosts\n\
    \        -- Or override with p_api_host parameter\n        --\n        -- Example:\n\
    \        --   SELECT rem_query('LOOKUP sarah-chen', 'user123');\n        --  \
    \ SELECT rem_query('SEARCH resources ''API design'' LIMIT 5', 'user123');\n\n\
    \        EXECUTE $func$\n        CREATE OR REPLACE FUNCTION rem_query(\n     \
    \       p_query TEXT,\n            p_user_id TEXT,\n            p_api_host TEXT\
    \ DEFAULT 'rem-api',\n            p_api_port INTEGER DEFAULT 8000,\n         \
    \   p_mode TEXT DEFAULT 'rem-dialect'\n        )\n        RETURNS BIGINT AS $inner$\n\
    \        DECLARE\n            api_url TEXT;\n            request_body JSONB;\n\
    \            request_headers JSONB;\n            request_id BIGINT;\n        BEGIN\n\
    \            -- Build API URL\n            -- Default: http://rem-api:8000/api/v1/query\
    \ (K8s same namespace)\n            api_url := format('http://%s:%s/api/v1/query',\
    \ p_api_host, p_api_port);\n\n            -- Build request body\n            request_body\
    \ := jsonb_build_object(\n                'query', p_query,\n                'mode',\
    \ p_mode\n            );\n\n            -- Build headers with user ID\n      \
    \      request_headers := jsonb_build_object(\n                'Content-Type',\
    \ 'application/json',\n                'X-User-Id', p_user_id\n            );\n\
    \n            -- Make async HTTP POST request\n            SELECT net.http_post(\n\
    \                url := api_url,\n                headers := request_headers,\n\
    \                body := request_body\n            ) INTO request_id;\n\n    \
    \        RETURN request_id;\n        END;\n        $inner$ LANGUAGE plpgsql;\n\
    \        $func$;\n\n        RAISE NOTICE '  rem_query() function created';\n\n\
    \        -- Helper to get query results (waits for async response)\n        --\
    \ NOTE: pg_net is async by design. This function polls for the response.\n   \
    \     -- For best results, use rem_query() and check results later, or use longer\
    \ timeouts.\n        EXECUTE $func$\n        CREATE OR REPLACE FUNCTION rem_query_result(\n\
    \            p_request_id BIGINT,\n            p_timeout_ms INTEGER DEFAULT 10000\n\
    \        )\n        RETURNS JSONB AS $inner$\n        DECLARE\n            v_status_code\
    \ INTEGER;\n            v_content TEXT;\n            v_found BOOLEAN;\n      \
    \      start_time TIMESTAMP;\n            elapsed_ms INTEGER;\n        BEGIN\n\
    \            start_time := clock_timestamp();\n\n            -- Poll for response\
    \ with timeout\n            -- Each iteration starts a new query to see committed\
    \ data from background worker\n            LOOP\n                -- Check if response\
    \ exists (background worker commits independently)\n                SELECT true,\
    \ status_code, content::text\n                INTO v_found, v_status_code, v_content\n\
    \                FROM net._http_response\n                WHERE id = p_request_id;\n\
    \n                -- Found response\n                IF v_found THEN\n       \
    \             IF v_status_code = 200 THEN\n                        RETURN v_content::jsonb;\n\
    \                    ELSE\n                        RETURN jsonb_build_object(\n\
    \                            'error', true,\n                            'status_code',\
    \ v_status_code,\n                            'content', v_content\n         \
    \               );\n                    END IF;\n                END IF;\n\n \
    \               -- Check timeout\n                elapsed_ms := EXTRACT(EPOCH\
    \ FROM (clock_timestamp() - start_time)) * 1000;\n                IF elapsed_ms\
    \ >= p_timeout_ms THEN\n                    RETURN jsonb_build_object(\n     \
    \                   'error', true,\n                        'message', 'Request\
    \ timeout - pg_net is async, response may arrive later',\n                   \
    \     'request_id', p_request_id,\n                        'hint', 'Check net._http_response\
    \ table or increase timeout'\n                    );\n                END IF;\n\
    \n                -- Wait 500ms before next poll (pg_net worker runs every 100ms)\n\
    \                PERFORM pg_sleep(0.5);\n            END LOOP;\n        END;\n\
    \        $inner$ LANGUAGE plpgsql;\n        $func$;\n\n        RAISE NOTICE '\
    \  rem_query_result() function created';\n\n        -- Convenience function: execute\
    \ query and wait for result\n        -- WARNING: Due to PostgreSQL transaction\
    \ isolation, this may timeout even when\n        -- the request succeeds. The\
    \ background worker commits separately and the polling\n        -- loop may not\
    \ see the response. Use rem_query() + check net._http_response for\n        --\
    \ more reliable async operation.\n        EXECUTE $func$\n        CREATE OR REPLACE\
    \ FUNCTION rem_query_sync(\n            p_query TEXT,\n            p_user_id TEXT,\n\
    \            p_api_host TEXT DEFAULT 'rem-api',\n            p_api_port INTEGER\
    \ DEFAULT 8000,\n            p_mode TEXT DEFAULT 'rem-dialect',\n            p_timeout_ms\
    \ INTEGER DEFAULT 10000\n        )\n        RETURNS JSONB AS $inner$\n       \
    \ DECLARE\n            request_id BIGINT;\n            v_status_code INTEGER;\n\
    \            v_content TEXT;\n            v_found BOOLEAN := false;\n        \
    \    start_time TIMESTAMP;\n            elapsed_ms INTEGER;\n        BEGIN\n \
    \           -- Execute query - this queues the HTTP request\n            request_id\
    \ := rem_query(p_query, p_user_id, p_api_host, p_api_port, p_mode);\n\n      \
    \      -- Wait for response with explicit snapshot refresh attempts\n        \
    \    start_time := clock_timestamp();\n            LOOP\n                -- Query\
    \ in separate subtransaction-like context\n                SELECT true, status_code,\
    \ content::text\n                INTO v_found, v_status_code, v_content\n    \
    \            FROM net._http_response\n                WHERE id = request_id;\n\
    \n                IF v_found THEN\n                    IF v_status_code = 200\
    \ THEN\n                        RETURN v_content::jsonb;\n                   \
    \ ELSE\n                        RETURN jsonb_build_object('error', true, 'status_code',\
    \ v_status_code, 'content', v_content);\n                    END IF;\n       \
    \         END IF;\n\n                elapsed_ms := EXTRACT(EPOCH FROM (clock_timestamp()\
    \ - start_time)) * 1000;\n                IF elapsed_ms >= p_timeout_ms THEN\n\
    \                    -- Return info about the async request so caller can check\
    \ later\n                    RETURN jsonb_build_object(\n                    \
    \    'pending', true,\n                        'request_id', request_id,\n   \
    \                     'message', 'Request queued but response not yet visible\
    \ due to transaction isolation',\n                        'hint', 'Query net._http_response\
    \ WHERE id = ' || request_id || ' after this transaction commits'\n          \
    \          );\n                END IF;\n\n                PERFORM pg_sleep(0.3);\n\
    \            END LOOP;\n        END;\n        $inner$ LANGUAGE plpgsql;\n    \
    \    $func$;\n\n        RAISE NOTICE '  rem_query_sync() function created (async\
    \ pattern recommended)';\n\n    ELSE\n        RAISE NOTICE '  Skipping pg_net\
    \ helper functions (extension not installed)';\n    END IF;\nEND $$;\n\n-- ============================================================================\n\
    -- RECORD INSTALLATION\n-- ============================================================================\n\
    \nDO $$\nBEGIN\n    -- Only record if migrations table exists\n    IF EXISTS (SELECT\
    \ 1 FROM information_schema.tables WHERE table_name = 'rem_migrations') THEN\n\
    \        INSERT INTO rem_migrations (name, type, version)\n        VALUES ('003_optional_extensions.sql',\
    \ 'install', '1.0.0')\n        ON CONFLICT (name) DO UPDATE\n        SET applied_at\
    \ = CURRENT_TIMESTAMP,\n            applied_by = CURRENT_USER;\n    END IF;\n\
    END $$;\n\n-- ============================================================================\n\
    -- COMPLETION\n-- ============================================================================\n\
    \nDO $$\nDECLARE\n    pg_net_installed BOOLEAN;\nBEGIN\n    SELECT EXISTS (SELECT\
    \ 1 FROM pg_extension WHERE extname = 'pg_net') INTO pg_net_installed;\n\n   \
    \ RAISE NOTICE '============================================================';\n\
    \    RAISE NOTICE 'Optional Extensions Installation Complete';\n    RAISE NOTICE\
    \ '============================================================';\n    RAISE NOTICE\
    \ '';\n    IF pg_net_installed THEN\n        RAISE NOTICE 'Installed:';\n    \
    \    RAISE NOTICE '  pg_net (async HTTP/HTTPS requests)';\n        RAISE NOTICE\
    \ '  rem_http_post() - POST JSON to URL';\n        RAISE NOTICE '  rem_http_get()\
    \ - GET from URL';\n        RAISE NOTICE '  rem_query() - Execute REM query (async)';\n\
    \        RAISE NOTICE '  rem_query_result() - Get async query result';\n     \
    \   RAISE NOTICE '  rem_query_sync() - Execute and wait for result';\n    ELSE\n\
    \        RAISE NOTICE 'Skipped (not available in this PostgreSQL image):';\n \
    \       RAISE NOTICE '  pg_net';\n        RAISE NOTICE '';\n        RAISE NOTICE\
    \ 'To enable pg_net, use the custom image: percolationlabs/rem-pg:18';\n    END\
    \ IF;\n    RAISE NOTICE '============================================================';\n\
    END $$;\n"
